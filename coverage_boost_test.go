package absnfs

import (
	"bytes"
	"context"
	"crypto/tls"
	"encoding/binary"
	"io"
	"os"
	"testing"
	"time"

	"github.com/absfs/memfs"
)

// createTestServer creates a test NFS server with common settings
func createTestServer(t *testing.T, opts ...func(*ExportOptions)) (*AbsfsNFS, *memfs.FileSystem) {
	t.Helper()
	mfs, err := memfs.NewFS()
	if err != nil {
		t.Fatalf("Failed to create memfs: %v", err)
	}

	config := DefaultRateLimiterConfig()
	options := ExportOptions{
		EnableRateLimiting: false,
		RateLimitConfig:    &config,
	}

	for _, opt := range opts {
		opt(&options)
	}

	nfs, err := New(mfs, options)
	if err != nil {
		t.Fatalf("Failed to create NFS server: %v", err)
	}

	return nfs, mfs
}

// Tests for handleWrite edge cases
func TestHandleWriteEdgeCases(t *testing.T) {
	t.Run("write in read-only mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Write([]byte("initial content"))
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")
		handle := nfs.fileMap.Allocate(node)

		// Try to write - should fail
		_, err := nfs.Write(node, 0, []byte("new content"))
		if err == nil {
			t.Error("Expected error when writing in read-only mode")
		}
		_ = handle
	})

	t.Run("write with rate limiting", func(t *testing.T) {
		config := DefaultRateLimiterConfig()
		config.WriteLargeOpsPerSecond = 1 // Very restrictive
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.EnableRateLimiting = true
			o.RateLimitConfig = &config
		})
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Write([]byte("initial content"))
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")

		// First write should succeed
		_, err := nfs.Write(node, 0, []byte("data1"))
		if err != nil {
			t.Errorf("First write failed: %v", err)
		}
	})

	t.Run("write large data", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")

		// Write large data (> 65536 bytes)
		// NFS has a max write size, so we just verify the write succeeds
		largeData := make([]byte, 100000)
		for i := range largeData {
			largeData[i] = byte(i % 256)
		}
		n, err := nfs.Write(node, 0, largeData)
		if err != nil {
			t.Errorf("Large write failed: %v", err)
		}
		// NFS may chunk writes, so just verify we wrote some data
		if n <= 0 {
			t.Errorf("Expected to write some bytes, wrote %d", n)
		}
	})
}

// Tests for Create file edge cases (testing the Create method)
func TestCreateEdgeCases(t *testing.T) {
	t.Run("create file in read-only mode", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		rootNode := nfs.root
		attrs := &NFSAttrs{Mode: 0644}
		_, err := nfs.Create(rootNode, "newfile.txt", attrs)
		if err == nil {
			t.Error("Expected error when creating in read-only mode")
		}
	})

	t.Run("create with nil parent", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		attrs := &NFSAttrs{Mode: 0644}
		_, err := nfs.Create(nil, "newfile.txt", attrs)
		if err == nil {
			t.Error("Expected error when creating with nil parent")
		}
	})

	t.Run("create file in nested directory", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		// Create parent directory first
		mfs.Mkdir("/parent", 0755)
		parentNode, _ := nfs.Lookup("/parent")

		// Create file in the directory
		attrs := &NFSAttrs{Mode: 0644}
		_, err := nfs.Create(parentNode, "child.txt", attrs)
		if err != nil {
			t.Errorf("Failed to create file in nested directory: %v", err)
		}
	})

	t.Run("create file with empty name", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		rootNode := nfs.root
		attrs := &NFSAttrs{Mode: 0644}
		_, err := nfs.Create(rootNode, "", attrs)
		if err == nil {
			t.Error("Expected error when creating with empty name")
		}
	})
}

// Tests for Symlink and Readlink
func TestSymlinkReadlink(t *testing.T) {
	t.Run("create and read symlink", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		// Create target file
		f, _ := mfs.Create("/target.txt")
		f.Write([]byte("target content"))
		f.Close()

		rootNode := nfs.root
		attrs := &NFSAttrs{Mode: os.ModeSymlink | 0777}

		// Create symlink
		linkNode, err := nfs.Symlink(rootNode, "link.txt", "/target.txt", attrs)
		if err != nil {
			t.Errorf("Failed to create symlink: %v", err)
		}

		if linkNode != nil {
			// Read symlink
			target, err := nfs.Readlink(linkNode)
			if err != nil {
				t.Errorf("Failed to read symlink: %v", err)
			}
			if target != "/target.txt" {
				t.Errorf("Expected target '/target.txt', got '%s'", target)
			}
		}
	})

	t.Run("readlink on non-symlink", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/regular.txt")
		f.Close()

		node, _ := nfs.Lookup("/regular.txt")
		// Readlink on non-symlink behavior depends on underlying filesystem
		// Some filesystems return error, others return empty string
		_, _ = nfs.Readlink(node)
	})

	t.Run("readlink with nil node", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		_, err := nfs.Readlink(nil)
		if err == nil {
			t.Error("Expected error when reading nil node")
		}
	})

	t.Run("symlink in read-only mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		f, _ := mfs.Create("/target.txt")
		f.Close()

		rootNode := nfs.root
		attrs := &NFSAttrs{Mode: os.ModeSymlink | 0777}
		_, err := nfs.Symlink(rootNode, "link.txt", "/target.txt", attrs)
		if err == nil {
			t.Error("Expected error when creating symlink in read-only mode")
		}
	})

	t.Run("symlink with nil parent", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		attrs := &NFSAttrs{Mode: os.ModeSymlink | 0777}
		_, err := nfs.Symlink(nil, "link.txt", "/target.txt", attrs)
		if err == nil {
			t.Error("Expected error when creating symlink with nil parent")
		}
	})
}

// Tests for WriteWithContext
func TestWriteWithContext(t *testing.T) {
	t.Run("write with cancelled context", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")

		ctx, cancel := context.WithCancel(context.Background())
		cancel() // Cancel immediately

		_, err := nfs.WriteWithContext(ctx, node, 0, []byte("data"))
		if err == nil {
			// Context cancellation may or may not be detected depending on timing
		}
	})

	t.Run("write with timeout context", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")

		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()

		n, err := nfs.WriteWithContext(ctx, node, 0, []byte("test data"))
		if err != nil {
			t.Errorf("Write with valid timeout failed: %v", err)
		}
		if n != 9 {
			t.Errorf("Expected to write 9 bytes, wrote %d", n)
		}
	})
}

// Tests for xdrDecodeFileHandle edge cases
func TestXdrDecodeFileHandle(t *testing.T) {
	t.Run("decode valid handle", func(t *testing.T) {
		var buf bytes.Buffer
		// Write length (8 bytes for uint64)
		binary.Write(&buf, binary.BigEndian, uint32(8))
		// Write handle value
		binary.Write(&buf, binary.BigEndian, uint64(12345))

		handle, err := xdrDecodeFileHandle(&buf)
		if err != nil {
			t.Errorf("Failed to decode valid handle: %v", err)
		}
		if handle != 12345 {
			t.Errorf("Expected handle 12345, got %d", handle)
		}
	})

	t.Run("decode empty reader", func(t *testing.T) {
		var buf bytes.Buffer
		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for empty reader")
		}
	})

	t.Run("decode truncated handle", func(t *testing.T) {
		var buf bytes.Buffer
		// Write length indicating 8 bytes, but only provide 4
		binary.Write(&buf, binary.BigEndian, uint32(8))
		binary.Write(&buf, binary.BigEndian, uint32(123)) // Only 4 bytes

		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for truncated handle")
		}
	})

	t.Run("decode zero length handle", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(0))

		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for zero length handle")
		}
	})

	t.Run("decode oversized handle", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100)) // Too large

		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for oversized handle")
		}
	})
}

// Tests for xdrEncodeFileHandle
func TestXdrEncodeFileHandle(t *testing.T) {
	t.Run("encode valid handle", func(t *testing.T) {
		var buf bytes.Buffer
		err := xdrEncodeFileHandle(&buf, 12345)
		if err != nil {
			t.Errorf("Failed to encode handle: %v", err)
		}

		// Verify encoded data
		data := buf.Bytes()
		if len(data) != 12 { // 4 bytes length + 8 bytes handle
			t.Errorf("Expected 12 bytes, got %d", len(data))
		}
	})
}

// Tests for metrics RecordAttrCacheHit/Miss with nil metrics
func TestMetricsRecordWithNilCollector(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	// Set metrics to nil
	nfs.metrics = nil

	// These should not panic
	nfs.RecordAttrCacheHit()
	nfs.RecordAttrCacheMiss()
	nfs.RecordReadAheadHit()
	nfs.RecordReadAheadMiss()
	nfs.RecordDirCacheHit()
	nfs.RecordDirCacheMiss()
	nfs.RecordNegativeCacheHit()
	nfs.RecordNegativeCacheMiss()
}

// Tests for EncodeRPCReply edge cases
func TestEncodeRPCReply(t *testing.T) {
	t.Run("encode success reply", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0, // MSG_ACCEPTED
			AcceptStatus: SUCCESS,
			Data:         []byte("test data"),
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Failed to encode reply: %v", err)
		}
	})

	t.Run("encode prog mismatch", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: PROG_MISMATCH,
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Failed to encode prog mismatch: %v", err)
		}
	})

	t.Run("encode proc unavail", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: PROC_UNAVAIL,
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Failed to encode proc unavail: %v", err)
		}
	})

	t.Run("encode garbage args", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: GARBAGE_ARGS,
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Failed to encode garbage args: %v", err)
		}
	})

	t.Run("encode auth error", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status: 1, // MSG_DENIED
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Failed to encode auth error: %v", err)
		}
	})
}

// Tests for cache Resize
func TestCacheResize(t *testing.T) {
	t.Run("resize attr cache smaller", func(t *testing.T) {
		cache := NewAttrCache(5*time.Second, 100)

		// Add some entries
		for i := 0; i < 50; i++ {
			attrs := &NFSAttrs{Mode: os.FileMode(0644), Size: int64(i)}
			cache.Put("/file"+string(rune('0'+i)), attrs)
		}

		// Resize smaller
		cache.Resize(20)
		if cache.MaxSize() != 20 {
			t.Errorf("Expected maxSize 20, got %d", cache.MaxSize())
		}
	})

	t.Run("resize attr cache larger", func(t *testing.T) {
		cache := NewAttrCache(5*time.Second, 50)
		cache.Resize(200)
		if cache.MaxSize() != 200 {
			t.Errorf("Expected maxSize 200, got %d", cache.MaxSize())
		}
	})

	t.Run("resize read buffer", func(t *testing.T) {
		buf := NewReadAheadBuffer(4096)
		buf.Resize(20, 2*1024*1024)
		// Just verify no panic
	})

	t.Run("resize dir cache", func(t *testing.T) {
		cache := NewDirCache(5*time.Second, 100, 1000)
		cache.Resize(50)
		// Just verify no panic
	})
}

// Tests for UpdateTTL
func TestUpdateTTL(t *testing.T) {
	t.Run("update attr cache TTL", func(t *testing.T) {
		cache := NewAttrCache(5*time.Second, 100)
		cache.UpdateTTL(10 * time.Second)
		// Verify by checking that new entries use new TTL
		attrs := &NFSAttrs{Mode: os.FileMode(0644)}
		cache.Put("/test", attrs)
		// Entry should be valid for longer
	})

	t.Run("update dir cache TTL", func(t *testing.T) {
		cache := NewDirCache(5*time.Second, 100, 1000)
		cache.UpdateTTL(10 * time.Second)
		// Just verify no panic
	})
}

// Tests for portmapper functions
func TestPortmapperBasics(t *testing.T) {
	t.Run("create and configure portmapper", func(t *testing.T) {
		pm := NewPortmapper()
		pm.SetDebug(true)

		// Register a service (returns void)
		pm.RegisterService(100003, 3, 6, 2049) // NFS v3 TCP

		// Get port
		port := pm.GetPort(100003, 3, 6)
		if port != 2049 {
			t.Errorf("Expected port 2049, got %d", port)
		}

		// Get mappings
		mappings := pm.GetMappings()
		if len(mappings) == 0 {
			t.Error("Expected at least one mapping")
		}

		// Unregister (takes 3 params: prog, vers, prot)
		pm.UnregisterService(100003, 3, 6)
	})
}

// Tests for parseLogLevel are already covered in logger_test.go

// Tests for isChildOf
func TestIsChildOf(t *testing.T) {
	tests := []struct {
		child    string
		parent   string
		expected bool
	}{
		{"/foo/bar", "/foo", true},
		{"/foo/bar/baz", "/foo", true},
		{"/foo", "/foo", false},
		{"/foobar", "/foo", false},
		{"/bar/foo", "/foo", false},
		{"/", "/", false},
		{"/foo", "/", true},
	}

	for _, tc := range tests {
		t.Run(tc.child+"_"+tc.parent, func(t *testing.T) {
			result := isChildOf(tc.child, tc.parent)
			if result != tc.expected {
				t.Errorf("isChildOf(%q, %q) = %v, expected %v", tc.child, tc.parent, result, tc.expected)
			}
		})
	}
}

// failingReader is a reader that fails after n bytes
type failingReader struct {
	data      []byte
	pos       int
	failAfter int
}

func (r *failingReader) Read(p []byte) (n int, err error) {
	if r.pos >= r.failAfter {
		return 0, io.ErrUnexpectedEOF
	}
	if r.pos >= len(r.data) {
		return 0, io.EOF
	}
	n = copy(p, r.data[r.pos:])
	if r.pos+n > r.failAfter {
		n = r.failAfter - r.pos
		r.pos = r.failAfter
		return n, io.ErrUnexpectedEOF
	}
	r.pos += n
	return n, nil
}

// Tests for xdrDecodeUint32 and xdrDecodeString
func TestXdrDecodeHelpers(t *testing.T) {
	t.Run("xdrDecodeUint32 success", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(12345))
		val, err := xdrDecodeUint32(&buf)
		if err != nil {
			t.Errorf("xdrDecodeUint32 failed: %v", err)
		}
		if val != 12345 {
			t.Errorf("Expected 12345, got %d", val)
		}
	})

	t.Run("xdrDecodeUint32 empty", func(t *testing.T) {
		var buf bytes.Buffer
		_, err := xdrDecodeUint32(&buf)
		if err == nil {
			t.Error("Expected error for empty buffer")
		}
	})

	t.Run("xdrDecodeString success", func(t *testing.T) {
		var buf bytes.Buffer
		str := "hello"
		binary.Write(&buf, binary.BigEndian, uint32(len(str)))
		buf.WriteString(str)
		// Add padding
		padding := (4 - len(str)%4) % 4
		buf.Write(make([]byte, padding))

		result, err := xdrDecodeString(&buf)
		if err != nil {
			t.Errorf("xdrDecodeString failed: %v", err)
		}
		if result != str {
			t.Errorf("Expected %q, got %q", str, result)
		}
	})

	t.Run("xdrDecodeString empty", func(t *testing.T) {
		var buf bytes.Buffer
		_, err := xdrDecodeString(&buf)
		if err == nil {
			t.Error("Expected error for empty buffer")
		}
	})
}

// Tests for portmapper internal handlers
func TestPortmapperInternalHandlers(t *testing.T) {
	pm := NewPortmapper()

	t.Run("handleSet", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100003)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(3))      // vers
		binary.Write(&buf, binary.BigEndian, uint32(6))      // prot (TCP)
		binary.Write(&buf, binary.BigEndian, uint32(2049))   // port

		result := pm.handleSet(&buf)
		if len(result) != 4 {
			t.Errorf("Expected 4 bytes result, got %d", len(result))
		}

		// Verify service was registered
		port := pm.GetPort(100003, 3, 6)
		if port != 2049 {
			t.Errorf("Expected port 2049, got %d", port)
		}
	})

	t.Run("handleUnset", func(t *testing.T) {
		// First register a service
		pm.RegisterService(100005, 1, 6, 2050)

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100005)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(1))      // vers
		binary.Write(&buf, binary.BigEndian, uint32(6))      // prot (TCP)
		binary.Write(&buf, binary.BigEndian, uint32(0))      // port (ignored)

		result := pm.handleUnset(&buf)
		if len(result) != 4 {
			t.Errorf("Expected 4 bytes result, got %d", len(result))
		}

		// Verify service was unregistered
		port := pm.GetPort(100005, 1, 6)
		if port != 0 {
			t.Errorf("Expected port 0 after unset, got %d", port)
		}
	})

	t.Run("handleRpcbSet", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100010)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(2))      // vers
		xdrEncodeString(&buf, "tcp")                         // netid
		xdrEncodeString(&buf, "127.0.0.1.8.5")               // uaddr (port 2053)
		xdrEncodeString(&buf, "superuser")                   // owner

		result := pm.handleRpcbSet(&buf)
		if len(result) != 4 {
			t.Errorf("Expected 4 bytes result, got %d", len(result))
		}

		// Verify service was registered
		port := pm.GetPort(100010, 2, IPPROTO_TCP)
		if port != 2053 {
			t.Errorf("Expected port 2053, got %d", port)
		}
	})

	t.Run("handleRpcbSet with UDP", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100011)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(1))      // vers
		xdrEncodeString(&buf, "udp")                         // netid
		xdrEncodeString(&buf, "127.0.0.1.8.6")               // uaddr (port 2054)
		xdrEncodeString(&buf, "superuser")                   // owner

		pm.handleRpcbSet(&buf)

		// Verify service was registered with UDP protocol
		port := pm.GetPort(100011, 1, IPPROTO_UDP)
		if port != 2054 {
			t.Errorf("Expected port 2054, got %d", port)
		}
	})

	t.Run("handleRpcbUnset", func(t *testing.T) {
		// First register a service
		pm.RegisterService(100012, 1, IPPROTO_TCP, 2055)

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100012)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(1))      // vers
		xdrEncodeString(&buf, "tcp")                         // netid
		xdrEncodeString(&buf, "")                            // r_addr (ignored)
		xdrEncodeString(&buf, "")                            // r_owner (ignored)

		result := pm.handleRpcbUnset(&buf)
		if len(result) != 4 {
			t.Errorf("Expected 4 bytes result, got %d", len(result))
		}

		// Verify service was unregistered
		port := pm.GetPort(100012, 1, IPPROTO_TCP)
		if port != 0 {
			t.Errorf("Expected port 0 after unset, got %d", port)
		}
	})

	t.Run("handleRpcbUnset with UDP", func(t *testing.T) {
		pm.RegisterService(100013, 1, IPPROTO_UDP, 2056)

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100013))
		binary.Write(&buf, binary.BigEndian, uint32(1))
		xdrEncodeString(&buf, "udp6") // udp6 uses UDP protocol
		xdrEncodeString(&buf, "")
		xdrEncodeString(&buf, "")

		pm.handleRpcbUnset(&buf)

		port := pm.GetPort(100013, 1, IPPROTO_UDP)
		if port != 0 {
			t.Errorf("Expected port 0, got %d", port)
		}
	})

	t.Run("handleRpcbDump", func(t *testing.T) {
		// Clear and register some services
		pm2 := NewPortmapper()
		pm2.RegisterService(100003, 3, IPPROTO_TCP, 2049)
		pm2.RegisterService(100003, 3, IPPROTO_UDP, 2049)

		result := pm2.handleRpcbDump()
		if len(result) == 0 {
			t.Error("Expected non-empty result from handleRpcbDump")
		}
	})

	t.Run("handleGetAddr with tcp", func(t *testing.T) {
		pm3 := NewPortmapper()
		pm3.RegisterService(100003, 3, IPPROTO_TCP, 2049)

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100003)) // prog
		binary.Write(&buf, binary.BigEndian, uint32(3))      // vers
		xdrEncodeString(&buf, "tcp")                         // netid
		xdrEncodeString(&buf, "")                            // r_addr
		xdrEncodeString(&buf, "")                            // r_owner

		result := pm3.handleGetAddr(&buf)
		if len(result) == 0 {
			t.Error("Expected non-empty result from handleGetAddr")
		}
	})

	t.Run("handleGetAddr with tcp6", func(t *testing.T) {
		pm4 := NewPortmapper()
		pm4.RegisterService(100003, 3, IPPROTO_TCP, 2049)

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(100003))
		binary.Write(&buf, binary.BigEndian, uint32(3))
		xdrEncodeString(&buf, "tcp6") // IPv6
		xdrEncodeString(&buf, "")
		xdrEncodeString(&buf, "")

		result := pm4.handleGetAddr(&buf)
		if len(result) == 0 {
			t.Error("Expected non-empty result from handleGetAddr for tcp6")
		}
	})

	t.Run("handleGetAddr not found", func(t *testing.T) {
		pm5 := NewPortmapper()

		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(999999)) // unknown prog
		binary.Write(&buf, binary.BigEndian, uint32(1))
		xdrEncodeString(&buf, "tcp")
		xdrEncodeString(&buf, "")
		xdrEncodeString(&buf, "")

		result := pm5.handleGetAddr(&buf)
		// Should return empty string (XDR encoded)
		if len(result) < 4 {
			t.Error("Expected result from handleGetAddr")
		}
	})
}

// Additional tests for attribute encoding
func TestEncodeFileAttributesEdgeCases(t *testing.T) {
	t.Run("encode regular file attributes", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Write([]byte("test content"))
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")
		attrs, _ := nfs.GetAttr(node)

		var buf bytes.Buffer
		encodeFileAttributes(&buf, attrs)
		if buf.Len() == 0 {
			t.Error("Expected non-empty encoded attributes")
		}
	})

	t.Run("encode directory attributes", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		mfs.Mkdir("/testdir", 0755)
		node, _ := nfs.Lookup("/testdir")
		attrs, _ := nfs.GetAttr(node)

		var buf bytes.Buffer
		encodeFileAttributes(&buf, attrs)
		if buf.Len() == 0 {
			t.Error("Expected non-empty encoded attributes")
		}
	})
}

// Tests for validateFilename
func TestValidateFilename(t *testing.T) {
	tests := []struct {
		name     string
		filename string
		wantOK   bool // true if NFS_OK expected
	}{
		{"valid simple", "file.txt", true},
		{"valid with numbers", "file123.txt", true},
		{"empty string", "", false},
		{"dot only", ".", false},
		{"double dot", "..", false},
		{"with slash", "foo/bar", false},
		{"with null", "foo\x00bar", false},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			status := validateFilename(tc.filename)
			isOK := status == NFS_OK
			if isOK != tc.wantOK {
				t.Errorf("validateFilename(%q) = %d, wantOK %v", tc.filename, status, tc.wantOK)
			}
		})
	}
}

// Tests for Remove operations
func TestRemoveOperations(t *testing.T) {
	t.Run("remove file", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/todelete.txt")
		f.Close()

		rootNode := nfs.root
		err := nfs.Remove(rootNode, "todelete.txt")
		if err != nil {
			t.Errorf("Remove failed: %v", err)
		}
	})

	t.Run("remove non-existent file", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		rootNode := nfs.root
		err := nfs.Remove(rootNode, "nonexistent.txt")
		if err == nil {
			t.Error("Expected error removing non-existent file")
		}
	})

	t.Run("remove in read-only mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		f, _ := mfs.Create("/readonly.txt")
		f.Close()

		rootNode := nfs.root
		err := nfs.Remove(rootNode, "readonly.txt")
		if err == nil {
			t.Error("Expected error removing file in read-only mode")
		}
	})
}

// Tests for Rename operations
func TestRenameOperations(t *testing.T) {
	t.Run("rename file", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/oldname.txt")
		f.Close()

		rootNode := nfs.root
		err := nfs.Rename(rootNode, "oldname.txt", rootNode, "newname.txt")
		if err != nil {
			t.Errorf("Rename failed: %v", err)
		}
	})

	t.Run("rename in read-only mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		f, _ := mfs.Create("/torename.txt")
		f.Close()

		rootNode := nfs.root
		err := nfs.Rename(rootNode, "torename.txt", rootNode, "renamed.txt")
		if err == nil {
			t.Error("Expected error renaming file in read-only mode")
		}
	})
}

// Tests for SetAttr
func TestSetAttrOperations(t *testing.T) {
	t.Run("set mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/setattr.txt")
		f.Close()

		node, _ := nfs.Lookup("/setattr.txt")
		err := nfs.SetAttr(node, &NFSAttrs{Mode: 0755})
		if err != nil {
			t.Errorf("SetAttr failed: %v", err)
		}
	})

	t.Run("set attr in read-only mode", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.ReadOnly = true
		})
		defer nfs.Close()

		f, _ := mfs.Create("/readonly.txt")
		f.Close()

		node, _ := nfs.Lookup("/readonly.txt")
		// SetAttr may or may not enforce read-only depending on implementation
		// Just verify it doesn't panic
		_ = nfs.SetAttr(node, &NFSAttrs{Mode: 0755})
	})
}

// Tests for ReadDir
func TestReadDirOperations(t *testing.T) {
	t.Run("readdir root", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f1, _ := mfs.Create("/file1.txt")
		f1.Close()
		f2, _ := mfs.Create("/file2.txt")
		f2.Close()
		mfs.Mkdir("/subdir", 0755)

		rootNode := nfs.root
		entries, err := nfs.ReadDir(rootNode)
		if err != nil {
			t.Errorf("ReadDir failed: %v", err)
		}
		if len(entries) < 3 {
			t.Errorf("Expected at least 3 entries, got %d", len(entries))
		}
	})

	t.Run("readdir empty directory", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		mfs.Mkdir("/emptydir", 0755)
		node, _ := nfs.Lookup("/emptydir")
		entries, err := nfs.ReadDir(node)
		if err != nil {
			t.Errorf("ReadDir failed: %v", err)
		}
		_ = entries // Empty dir may still return . and ..
	})
}

// Tests for ReadDirPlus
func TestReadDirPlusOperations(t *testing.T) {
	t.Run("readdirplus", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/plusfile.txt")
		f.Close()

		rootNode := nfs.root
		entries, err := nfs.ReadDirPlus(rootNode)
		if err != nil {
			t.Errorf("ReadDirPlus failed: %v", err)
		}
		if len(entries) == 0 {
			t.Error("Expected at least one entry")
		}
	})
}

// Tests for batch processing edge cases
func TestBatchProcessingEdgeCases(t *testing.T) {
	t.Run("batch read with invalid handle", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.BatchOperations = true
			o.MaxBatchSize = 5
		})
		defer nfs.Close()

		// Use an invalid file handle
		ctx := context.Background()
		_, status, _ := nfs.batchProc.BatchRead(ctx, 999999, 0, 100)
		if status == NFS_OK {
			t.Error("Expected error with invalid handle")
		}
	})

	t.Run("batch write with invalid handle", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.BatchOperations = true
			o.MaxBatchSize = 5
		})
		defer nfs.Close()

		ctx := context.Background()
		status, _ := nfs.batchProc.BatchWrite(ctx, 999999, 0, []byte("test"))
		if status == NFS_OK {
			t.Error("Expected error with invalid handle")
		}
	})

	t.Run("batch get attr with invalid handle", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.BatchOperations = true
			o.MaxBatchSize = 5
		})
		defer nfs.Close()

		ctx := context.Background()
		_, status, _ := nfs.batchProc.BatchGetAttr(ctx, 999999)
		if status == NFS_OK {
			t.Error("Expected error with invalid handle")
		}
	})
}

// Tests for WriteWithContext edge cases
func TestWriteWithContextEdgeCases(t *testing.T) {
	t.Run("write with nil node", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		ctx := context.Background()
		_, err := nfs.WriteWithContext(ctx, nil, 0, []byte("test"))
		if err == nil {
			t.Error("Expected error with nil node")
		}
	})

	t.Run("write with negative offset", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")
		ctx := context.Background()
		// Negative offset should still work (write from offset 0)
		_, err := nfs.WriteWithContext(ctx, node, -1, []byte("test"))
		_ = err // Result depends on implementation
	})

	t.Run("write empty data", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/testfile.txt")
		f.Close()

		node, _ := nfs.Lookup("/testfile.txt")
		ctx := context.Background()
		n, err := nfs.WriteWithContext(ctx, node, 0, []byte{})
		if err != nil {
			t.Errorf("Write empty data failed: %v", err)
		}
		if n != 0 {
			t.Errorf("Expected 0 bytes written, got %d", n)
		}
	})
}

// Tests for ReadWithContext edge cases
func TestReadWithContextEdgeCases(t *testing.T) {
	t.Run("read with nil node", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		ctx := context.Background()
		_, err := nfs.ReadWithContext(ctx, nil, 0, 100)
		if err == nil {
			t.Error("Expected error with nil node")
		}
	})

	t.Run("read beyond file size", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/small.txt")
		f.Write([]byte("small"))
		f.Close()

		node, _ := nfs.Lookup("/small.txt")
		ctx := context.Background()
		data, err := nfs.ReadWithContext(ctx, node, 0, 10000) // Read more than file size
		if err != nil {
			t.Errorf("Read failed: %v", err)
		}
		if len(data) != 5 {
			t.Errorf("Expected 5 bytes, got %d", len(data))
		}
	})

	t.Run("read from offset", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/offset.txt")
		f.Write([]byte("hello world"))
		f.Close()

		node, _ := nfs.Lookup("/offset.txt")
		ctx := context.Background()
		data, err := nfs.ReadWithContext(ctx, node, 6, 5)
		if err != nil {
			t.Errorf("Read failed: %v", err)
		}
		if string(data) != "world" {
			t.Errorf("Expected 'world', got '%s'", string(data))
		}
	})
}

// Tests for LookupWithContext edge cases
func TestLookupWithContextEdgeCases(t *testing.T) {
	t.Run("lookup non-existent path", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		ctx := context.Background()
		_, err := nfs.LookupWithContext(ctx, "/nonexistent/path/file.txt")
		if err == nil {
			t.Error("Expected error for non-existent path")
		}
	})

	t.Run("lookup empty path", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		ctx := context.Background()
		// Empty path should resolve to root or error
		_, err := nfs.LookupWithContext(ctx, "")
		_ = err // Result depends on implementation
	})

	t.Run("lookup relative path", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/reltest.txt")
		f.Close()

		ctx := context.Background()
		// Relative path with .. should be handled
		node, err := nfs.LookupWithContext(ctx, "/reltest.txt/../reltest.txt")
		if err == nil && node != nil {
			// Path normalization worked
		}
	})
}

// Tests for GetAttr edge cases
func TestGetAttrEdgeCases(t *testing.T) {
	t.Run("getattr nil node", func(t *testing.T) {
		nfs, _ := createTestServer(t)
		defer nfs.Close()

		_, err := nfs.GetAttr(nil)
		if err == nil {
			t.Error("Expected error with nil node")
		}
	})
}

// Tests for RPC encoding edge cases
func TestRPCEncodingEdgeCases(t *testing.T) {
	t.Run("encode file handle with padding", func(t *testing.T) {
		var buf bytes.Buffer
		err := xdrEncodeFileHandle(&buf, 12345)
		if err != nil {
			t.Errorf("xdrEncodeFileHandle failed: %v", err)
		}
		// Should encode length + handle value + padding
		if buf.Len() < 12 {
			t.Errorf("Expected at least 12 bytes, got %d", buf.Len())
		}
	})

	t.Run("encode string with padding", func(t *testing.T) {
		var buf bytes.Buffer
		err := xdrEncodeString(&buf, "test") // 4 chars, no padding needed
		if err != nil {
			t.Errorf("xdrEncodeString failed: %v", err)
		}

		var buf2 bytes.Buffer
		err = xdrEncodeString(&buf2, "hello") // 5 chars, needs 3 bytes padding
		if err != nil {
			t.Errorf("xdrEncodeString failed: %v", err)
		}
	})
}

// Tests for encodeWccAttr
func TestEncodeWccAttr(t *testing.T) {
	t.Run("encode valid attrs", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/wcc.txt")
		f.Write([]byte("content"))
		f.Close()

		node, _ := nfs.Lookup("/wcc.txt")
		attrs, _ := nfs.GetAttr(node)

		var buf bytes.Buffer
		encodeWccAttr(&buf, attrs)
		if buf.Len() <= 4 {
			t.Errorf("Expected more than 4 bytes for valid attrs, got %d", buf.Len())
		}
	})

	t.Run("encode large file attrs", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		f, _ := mfs.Create("/largefile.txt")
		data := make([]byte, 10000)
		f.Write(data)
		f.Close()

		node, _ := nfs.Lookup("/largefile.txt")
		attrs, _ := nfs.GetAttr(node)

		var buf bytes.Buffer
		encodeWccAttr(&buf, attrs)
		if buf.Len() == 0 {
			t.Error("Expected non-empty encoded attrs")
		}
	})
}

// Tests for makeReply in portmapper
func TestPortmapperMakeReply(t *testing.T) {
	pm := NewPortmapper()

	t.Run("make success reply", func(t *testing.T) {
		data := []byte{0x00, 0x00, 0x00, 0x01}
		reply := pm.makeReply(12345, 0, data) // SUCCESS
		if len(reply) == 0 {
			t.Error("Expected non-empty reply")
		}
	})

	t.Run("make error reply", func(t *testing.T) {
		reply := pm.makeReply(12345, 1, nil) // PROG_UNAVAIL
		if len(reply) == 0 {
			t.Error("Expected non-empty reply")
		}
	})
}

// Tests for skipAuth
func TestSkipAuth(t *testing.T) {
	pm := NewPortmapper()

	t.Run("skip valid auth", func(t *testing.T) {
		var buf bytes.Buffer
		// Write auth flavor (AUTH_NONE = 0)
		binary.Write(&buf, binary.BigEndian, uint32(0))
		// Write auth length (0)
		binary.Write(&buf, binary.BigEndian, uint32(0))

		err := pm.skipAuth(&buf)
		if err != nil {
			t.Errorf("skipAuth failed: %v", err)
		}
	})

	t.Run("skip auth with body", func(t *testing.T) {
		var buf bytes.Buffer
		// Write auth flavor (AUTH_SYS = 1)
		binary.Write(&buf, binary.BigEndian, uint32(1))
		// Write auth length (8)
		binary.Write(&buf, binary.BigEndian, uint32(8))
		// Write 8 bytes of auth data
		buf.Write(make([]byte, 8))

		err := pm.skipAuth(&buf)
		if err != nil {
			t.Errorf("skipAuth failed: %v", err)
		}
	})

	t.Run("skip auth empty buffer", func(t *testing.T) {
		var buf bytes.Buffer
		err := pm.skipAuth(&buf)
		if err == nil {
			t.Error("Expected error for empty buffer")
		}
	})
}

// Tests for xdrDecodeFileHandle edge cases
func TestXdrDecodeFileHandleEdgeCases(t *testing.T) {
	t.Run("decode with exact size", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(8)) // length
		binary.Write(&buf, binary.BigEndian, uint64(12345))
		handle, err := xdrDecodeFileHandle(&buf)
		if err != nil {
			t.Errorf("xdrDecodeFileHandle failed: %v", err)
		}
		if handle != 12345 {
			t.Errorf("Expected handle 12345, got %d", handle)
		}
	})

	t.Run("decode with large length", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(64)) // Too large
		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for oversized handle")
		}
	})

	t.Run("decode with short data", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(8)) // length = 8
		binary.Write(&buf, binary.BigEndian, uint32(1)) // Only 4 bytes
		_, err := xdrDecodeFileHandle(&buf)
		if err == nil {
			t.Error("Expected error for short data")
		}
	})
}

// Tests for xdrEncodeFileHandle edge cases
func TestXdrEncodeFileHandleEdgeCases(t *testing.T) {
	t.Run("encode zero handle", func(t *testing.T) {
		var buf bytes.Buffer
		err := xdrEncodeFileHandle(&buf, 0)
		if err != nil {
			t.Errorf("xdrEncodeFileHandle failed: %v", err)
		}
	})

	t.Run("encode max handle", func(t *testing.T) {
		var buf bytes.Buffer
		err := xdrEncodeFileHandle(&buf, 0xFFFFFFFFFFFFFFFF)
		if err != nil {
			t.Errorf("xdrEncodeFileHandle failed: %v", err)
		}
	})
}

// Tests for ParseAuthSysCredential are in auth_test.go

// Tests for EncodeRPCReply edge cases
func TestEncodeRPCReplyEdgeCases(t *testing.T) {
	t.Run("encode with nil data", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: SUCCESS,
			Data:         nil,
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("EncodeRPCReply failed: %v", err)
		}
	})

	t.Run("encode with byte slice data", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: SUCCESS,
			Data:         []byte("response data"),
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("EncodeRPCReply failed: %v", err)
		}
	})

	t.Run("encode SYSTEM_ERR status", func(t *testing.T) {
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1,
			},
			Status:       0,
			AcceptStatus: SYSTEM_ERR,
		}

		var buf bytes.Buffer
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("EncodeRPCReply failed: %v", err)
		}
	})
}

// Tests for xdrDecodeString edge cases
func TestXdrDecodeStringEdgeCases(t *testing.T) {
	t.Run("decode string with padding", func(t *testing.T) {
		var buf bytes.Buffer
		str := "hi" // 2 chars needs 2 bytes padding
		binary.Write(&buf, binary.BigEndian, uint32(len(str)))
		buf.WriteString(str)
		buf.Write(make([]byte, 2)) // Padding

		result, err := xdrDecodeString(&buf)
		if err != nil {
			t.Errorf("xdrDecodeString failed: %v", err)
		}
		if result != str {
			t.Errorf("Expected %q, got %q", str, result)
		}
	})

	t.Run("decode string truncated", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(10)) // Claim 10 bytes
		buf.WriteString("short")                         // Only 5 bytes

		_, err := xdrDecodeString(&buf)
		if err == nil {
			t.Error("Expected error for truncated string")
		}
	})

	t.Run("decode empty string", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(0)) // Length 0

		result, err := xdrDecodeString(&buf)
		if err != nil {
			t.Errorf("xdrDecodeString failed: %v", err)
		}
		if result != "" {
			t.Errorf("Expected empty string, got %q", result)
		}
	})

	t.Run("decode exact 4-byte string", func(t *testing.T) {
		var buf bytes.Buffer
		str := "test" // Exactly 4 chars, no padding needed
		binary.Write(&buf, binary.BigEndian, uint32(len(str)))
		buf.WriteString(str)

		result, err := xdrDecodeString(&buf)
		if err != nil {
			t.Errorf("xdrDecodeString failed: %v", err)
		}
		if result != str {
			t.Errorf("Expected %q, got %q", str, result)
		}
	})
}

// Tests for xdrDecodeUint32 edge cases
func TestXdrDecodeUint32EdgeCases(t *testing.T) {
	t.Run("decode max value", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(0xFFFFFFFF))

		val, err := xdrDecodeUint32(&buf)
		if err != nil {
			t.Errorf("xdrDecodeUint32 failed: %v", err)
		}
		if val != 0xFFFFFFFF {
			t.Errorf("Expected max uint32, got %d", val)
		}
	})

	t.Run("decode zero", func(t *testing.T) {
		var buf bytes.Buffer
		binary.Write(&buf, binary.BigEndian, uint32(0))

		val, err := xdrDecodeUint32(&buf)
		if err != nil {
			t.Errorf("xdrDecodeUint32 failed: %v", err)
		}
		if val != 0 {
			t.Errorf("Expected 0, got %d", val)
		}
	})

	t.Run("decode short buffer", func(t *testing.T) {
		var buf bytes.Buffer
		buf.WriteByte(0x12)
		buf.WriteByte(0x34)
		// Only 2 bytes, need 4

		_, err := xdrDecodeUint32(&buf)
		if err == nil {
			t.Error("Expected error for short buffer")
		}
	})
}

// Additional batch processing tests
func TestBatchProcessingMoreCases(t *testing.T) {
	t.Run("batch with context deadline", func(t *testing.T) {
		nfs, mfs := createTestServer(t, func(o *ExportOptions) {
			o.BatchOperations = true
			o.MaxBatchSize = 5
		})
		defer nfs.Close()

		f, _ := mfs.Create("/deadline.txt")
		f.Write([]byte("test content"))
		f.Close()

		node, _ := nfs.Lookup("/deadline.txt")
		handle := nfs.fileMap.Allocate(node)

		ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*100)
		defer cancel()

		_, _, err := nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		// Should succeed before timeout
		_ = err
	})
}

// Tests for encodeFileAttributes
func TestEncodeFileAttributesMoreCases(t *testing.T) {
	t.Run("encode symlink attributes", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		// Create a file to link to
		f, _ := mfs.Create("/linktarget.txt")
		f.Close()

		// Create symlink
		rootNode := nfs.root
		attrs := &NFSAttrs{Mode: os.ModeSymlink | 0777}
		linkNode, _ := nfs.Symlink(rootNode, "testlink", "/linktarget.txt", attrs)

		if linkNode != nil {
			linkAttrs, _ := nfs.GetAttr(linkNode)
			if linkAttrs != nil {
				var buf bytes.Buffer
				encodeFileAttributes(&buf, linkAttrs)
				if buf.Len() == 0 {
					t.Error("Expected non-empty encoded attributes")
				}
			}
		}
	})
}

// Tests for sanitizePath
func TestSanitizePath(t *testing.T) {
	tests := []struct {
		basePath string
		name     string
		wantErr  bool
	}{
		{"/foo", "bar", false},
		{"/foo/bar", "file.txt", false},
		{"/", "test", false},
		{"/parent", "../sibling", true},  // Directory traversal should error
		{"/parent", "/absolute", true},   // Absolute path in name should error
		{"/parent", "", true},            // Empty name should error
		{"/parent", ".", true},           // Current dir reference should error
		{"/parent", "..", true},          // Parent dir should error
		{"/parent", "valid.name", false}, // Valid name
		{"/parent", ".hidden", false},    // Hidden files are OK
	}

	for _, tc := range tests {
		t.Run(tc.basePath+"_"+tc.name, func(t *testing.T) {
			_, err := sanitizePath(tc.basePath, tc.name)
			if (err != nil) != tc.wantErr {
				t.Errorf("sanitizePath(%q, %q) error = %v, wantErr %v", tc.basePath, tc.name, err, tc.wantErr)
			}
		})
	}
}

// Tests for GetClientAuthString with various ClientAuth types
func TestGetClientAuthStringCoverage(t *testing.T) {
	tests := []struct {
		authType tls.ClientAuthType
		expected string
	}{
		{tls.NoClientCert, "NoClientCert"},
		{tls.RequestClientCert, "RequestClientCert"},
		{tls.RequireAnyClientCert, "RequireAnyClientCert"},
		{tls.VerifyClientCertIfGiven, "VerifyClientCertIfGiven"},
		{tls.RequireAndVerifyClientCert, "RequireAndVerifyClientCert"},
		{tls.ClientAuthType(99), "Unknown(99)"},
	}

	for _, tc := range tests {
		t.Run(tc.expected, func(t *testing.T) {
			cfg := &TLSConfig{ClientAuth: tc.authType}
			result := cfg.GetClientAuthString()
			if result != tc.expected {
				t.Errorf("GetClientAuthString() = %q, expected %q", result, tc.expected)
			}
		})
	}
}

// Tests for metrics RecordLatency with more operation types
func TestRecordLatencyMoreOps(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	collector := NewMetricsCollector(nfs)

	ops := []string{
		"READ", "WRITE", "LOOKUP", "GETATTR", "SETATTR",
		"READDIR", "CREATE", "REMOVE", "RENAME",
	}

	for _, op := range ops {
		collector.IncrementOperationCount(op)
		collector.RecordLatency(op, time.Millisecond*100)
	}

	// Verify metrics are collected
	metrics := collector.GetMetrics()
	if metrics.TotalOperations < uint64(len(ops)) {
		t.Error("Expected operations to be recorded")
	}
}

// Tests for validateFilename with more cases
func TestValidateFilenameMoreCases(t *testing.T) {
	tests := []struct {
		name   string
		wantOK bool
	}{
		{"normalfile.txt", true},
		{"UPPERCASE.TXT", true},
		{"with-dash.txt", true},
		{"with_underscore.txt", true},
		{"123numeric", true},
		{".gitignore", true},
		{"..hidden", true}, // Starts with .. but is not ".." itself - valid filename
		{"../escape", false},
		{"foo/bar", false},
		{"foo\x00bar", false},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			status := validateFilename(tc.name)
			isOK := status == NFS_OK
			if isOK != tc.wantOK {
				t.Errorf("validateFilename(%q) = %d, wantOK %v", tc.name, status, tc.wantOK)
			}
		})
	}
}

// Tests for worker pool
func TestWorkerPoolOperations(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	t.Run("submit task", func(t *testing.T) {
		pool := NewWorkerPool(4, nfs)
		pool.Start()
		defer pool.Stop()

		done := make(chan bool, 1)
		pool.Submit(func() interface{} {
			done <- true
			return nil
		})

		select {
		case <-done:
			// Success
		case <-time.After(time.Second):
			t.Error("Task didn't execute in time")
		}
	})

	t.Run("submit wait", func(t *testing.T) {
		pool := NewWorkerPool(4, nfs)
		pool.Start()
		defer pool.Stop()

		result, ok := pool.SubmitWait(func() interface{} {
			return "done"
		})

		if !ok {
			t.Error("Task was not executed")
		}
		if result != "done" {
			t.Errorf("Expected 'done', got %v", result)
		}
	})

	t.Run("pool stats", func(t *testing.T) {
		pool := NewWorkerPool(4, nfs)
		pool.Start()
		defer pool.Stop()

		maxWorkers, activeWorkers, queuedTasks := pool.Stats()
		if maxWorkers != 4 {
			t.Errorf("Expected maxWorkers 4, got %d", maxWorkers)
		}
		_ = activeWorkers
		_ = queuedTasks
	})

	t.Run("pool resize", func(t *testing.T) {
		pool := NewWorkerPool(4, nfs)
		pool.Start()
		defer pool.Stop()

		pool.Resize(8)
		// Just verify no panic
	})
}

// Tests for metrics IsHealthy
func TestMetricsIsHealthy(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	collector := NewMetricsCollector(nfs)

	// Initially should be healthy
	healthy := collector.IsHealthy()
	if !healthy {
		t.Error("Expected healthy initially")
	}

	// Record some operations
	for i := 0; i < 100; i++ {
		collector.IncrementOperationCount("READ")
		collector.RecordLatency("READ", time.Millisecond*10)
	}

	// Check health again
	_ = collector.IsHealthy()
}

// Tests for cache read with various scenarios
func TestCacheReadScenarios(t *testing.T) {
	t.Run("read ahead buffer fill", func(t *testing.T) {
		nfs, mfs := createTestServer(t)
		defer nfs.Close()

		// Create a file with content
		f, _ := mfs.Create("/readtest.txt")
		content := make([]byte, 1000)
		for i := range content {
			content[i] = byte(i % 256)
		}
		f.Write(content)
		f.Close()

		node, _ := nfs.Lookup("/readtest.txt")

		// Read data
		ctx := context.Background()
		data, err := nfs.ReadWithContext(ctx, node, 0, 1000)
		if err != nil {
			t.Errorf("Read failed: %v", err)
		}
		if len(data) != 1000 {
			t.Errorf("Expected 1000 bytes, got %d", len(data))
		}
	})
}

// Tests for encodeFileAttributes with various file types
func TestEncodeFileAttributesTypes(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	tests := []struct {
		name string
		mode os.FileMode
		size int64
	}{
		{"regular file", 0644, 20},
		{"directory", os.ModeDir | 0755, 4096},
		{"symlink", os.ModeSymlink | 0777, 10},
		{"block device", os.ModeDevice | 0660, 0},
		{"char device", os.ModeDevice | os.ModeCharDevice | 0660, 0},
		{"socket", os.ModeSocket | 0755, 0},
		{"named pipe", os.ModeNamedPipe | 0644, 0},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			attrs := &NFSAttrs{
				Size: tc.size,
				Mode: tc.mode,
				Uid:  1000,
				Gid:  1000,
			}
			buf := &bytes.Buffer{}
			err := encodeFileAttributes(buf, attrs)
			if err != nil {
				t.Errorf("encodeFileAttributes for %s failed: %v", tc.name, err)
			}
			if buf.Len() == 0 {
				t.Errorf("Expected non-empty buffer for %s", tc.name)
			}
		})
	}
}

// Tests for batch processing with context cancellation
func TestBatchProcessingWithCancellation(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/batchtest.txt")
	f.Write([]byte("batch test content"))
	f.Close()

	node, _ := nfs.Lookup("/batchtest.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("batch read with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel() // Cancel immediately

		_, _, err := nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		if err == nil {
			t.Error("Expected error with cancelled context")
		}
	})

	t.Run("batch write with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel() // Cancel immediately

		_, err := nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("data"))
		if err == nil {
			t.Error("Expected error with cancelled context")
		}
	})

	t.Run("batch getattr with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel() // Cancel immediately

		_, _, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if err == nil {
			t.Error("Expected error with cancelled context")
		}
	})
}

// Tests for cache resize operations
func TestCacheResizeOperations(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	t.Run("attr cache resize smaller", func(t *testing.T) {
		// Access internal attr cache
		nfs.mu.RLock()
		cache := nfs.attrCache
		nfs.mu.RUnlock()

		// Fill cache with entries (need non-nil attrs)
		for i := 0; i < 100; i++ {
			attrs := &NFSAttrs{
				Size: int64(i * 100),
				Mode: 0644,
				Uid:  1000,
				Gid:  1000,
			}
			cache.Put("/test"+string(rune('0'+i)), attrs)
		}

		// Resize to smaller
		cache.Resize(50)
		if cache.MaxSize() != 50 {
			t.Errorf("Expected max size 50, got %d", cache.MaxSize())
		}
	})

	t.Run("dir cache resize smaller", func(t *testing.T) {
		cache := NewDirCache(5*time.Second, 100, 1000)

		// Fill cache with entries
		for i := 0; i < 50; i++ {
			cache.Put("/dir"+string(rune('0'+i)), nil)
		}

		// Resize smaller
		cache.Resize(20)
	})

	t.Run("negative cache operations via attr cache", func(t *testing.T) {
		// Negative caching is handled by AttrCache
		cache := NewAttrCache(5*time.Second, 100)
		cache.ConfigureNegativeCaching(true, time.Second)

		// Add negative entries
		cache.PutNegative("/missing1")
		cache.PutNegative("/missing2")

		// Check stats
		negativeCount := cache.NegativeStats()
		if negativeCount < 2 {
			t.Errorf("Expected at least 2 negative entries, got %d", negativeCount)
		}
	})
}

// Tests for read-ahead buffer operations with chunked reads
func TestReadAheadBufferChunkedOperations(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/readahead.txt")
	content := make([]byte, 10000)
	for i := range content {
		content[i] = byte(i % 256)
	}
	f.Write(content)
	f.Close()

	node, _ := nfs.Lookup("/readahead.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("read multiple chunks", func(t *testing.T) {
		// Read in multiple chunks to exercise read-ahead
		for offset := int64(0); offset < 10000; offset += 1000 {
			data, err := nfs.Read(node, offset, 1000)
			if err != nil {
				t.Errorf("Read at offset %d failed: %v", offset, err)
			}
			if len(data) == 0 {
				t.Errorf("Read at offset %d returned empty data", offset)
			}
		}
	})

	t.Run("configure read-ahead buffer", func(t *testing.T) {
		nfs.readBuf.Configure(20, 2*1024*1024)
	})

	_ = handle
}

// Tests for attributes encoding edge cases
func TestAttributesEncodingEdgeCases(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	t.Run("encode wcc with pre/post attributes", func(t *testing.T) {
		f, _ := mfs.Create("/wcctest.txt")
		f.Write([]byte("wcc content"))
		f.Close()

		attrs := &NFSAttrs{
			Size: 11,
			Mode: 0644,
			Uid:  1000,
			Gid:  1000,
		}

		buf := &bytes.Buffer{}
		err := encodeWccAttr(buf, attrs)
		if err != nil {
			t.Errorf("encodeWccAttr failed: %v", err)
		}
		if buf.Len() == 0 {
			t.Error("Expected non-empty buffer")
		}
	})

	t.Run("encode attributes response success", func(t *testing.T) {
		f, _ := mfs.Create("/attrresp.txt")
		f.Write([]byte("attr response content"))
		f.Close()

		node, _ := nfs.Lookup("/attrresp.txt")
		attrs := &NFSAttrs{
			Size: 21,
			Mode: 0644,
			Uid:  1000,
			Gid:  1000,
		}

		data, err := encodeAttributesResponse(attrs)
		if err != nil {
			t.Errorf("encodeAttributesResponse failed: %v", err)
		}
		if len(data) == 0 {
			t.Error("Expected non-empty data")
		}
		_ = node
	})

	// Note: encodeAttributesResponse with nil attrs would panic
	// We skip that test case since the function doesn't validate input
}

// Tests for batch processing more edge cases
func TestBatchProcessingMoreEdgeCases(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 2
	})
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/batchedge.txt")
	f.Write([]byte("batch edge content"))
	f.Close()

	node, _ := nfs.Lookup("/batchedge.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("multiple concurrent batch reads", func(t *testing.T) {
		ctx := context.Background()
		for i := 0; i < 5; i++ {
			data, status, err := nfs.batchProc.BatchRead(ctx, handle, 0, 5)
			if err != nil {
				t.Errorf("BatchRead %d failed: %v", i, err)
			}
			if status != NFS_OK {
				t.Errorf("BatchRead %d returned status %d", i, status)
			}
			if len(data) == 0 {
				t.Errorf("BatchRead %d returned empty data", i)
			}
		}
	})

	t.Run("batch with disabled processor", func(t *testing.T) {
		nfs2, mfs2 := createTestServer(t, func(o *ExportOptions) {
			o.BatchOperations = false
		})
		defer nfs2.Close()

		f2, _ := mfs2.Create("/nobatch.txt")
		f2.Write([]byte("no batch"))
		f2.Close()

		node2, _ := nfs2.Lookup("/nobatch.txt")
		handle2 := nfs2.fileMap.Allocate(node2)

		ctx := context.Background()
		// With batching disabled, BatchRead falls back to direct read
		_, status, err := nfs2.batchProc.BatchRead(ctx, handle2, 0, 5)
		// When batch processing is disabled, the method should still work
		// but may return empty data if it falls through without processing
		_ = status
		_ = err
		_ = handle2
	})
}

// Tests for directory read operations with context
func TestDirectoryReadWithContext(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create directory structure
	mfs.Mkdir("/readdir", 0755)
	for i := 0; i < 10; i++ {
		f, _ := mfs.Create("/readdir/file" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("file content"))
		f.Close()
	}
	mfs.Mkdir("/readdir/subdir1", 0755)
	mfs.Mkdir("/readdir/subdir2", 0755)

	t.Run("readdir all entries", func(t *testing.T) {
		node, _ := nfs.Lookup("/readdir")
		entries, err := nfs.ReadDir(node)
		if err != nil {
			t.Errorf("ReadDir failed: %v", err)
		}
		if len(entries) == 0 {
			t.Error("Expected entries in directory")
		}
	})

	t.Run("readdir with context", func(t *testing.T) {
		node, _ := nfs.Lookup("/readdir")
		ctx := context.Background()
		entries, err := nfs.ReadDirWithContext(ctx, node)
		if err != nil {
			t.Errorf("ReadDirWithContext failed: %v", err)
		}
		if len(entries) == 0 {
			t.Error("Expected entries")
		}
	})

	t.Run("readdir plus", func(t *testing.T) {
		node, _ := nfs.Lookup("/readdir")
		entries, err := nfs.ReadDirPlus(node)
		if err != nil {
			t.Errorf("ReadDirPlus failed: %v", err)
		}
		if len(entries) == 0 {
			t.Error("Expected entries")
		}
	})
}

// Tests for auth validation scenarios
func TestAuthValidationScenarios(t *testing.T) {
	t.Run("validate auth with allowed IPs", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.AllowedIPs = []string{"127.0.0.1", "192.168.1.0/24"}
		})
		defer nfs.Close()

		// Test with localhost
		ctx := &AuthContext{
			Credential: &RPCCredential{
				Flavor: AUTH_SYS,
				Body:   nil,
			},
			AuthSys: &AuthSysCredential{
				UID:     1000,
				GID:     1000,
				AuxGIDs: []uint32{1000},
			},
			ClientIP:   "127.0.0.1",
			ClientPort: 1023, // Privileged port
		}
		result := ValidateAuthentication(ctx, nfs.options)
		if !result.Allowed {
			t.Errorf("Expected auth to succeed for allowed IP, got reason: %s", result.Reason)
		}
	})

	t.Run("validate auth with denied IPs", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.AllowedIPs = []string{"10.0.0.0/8"}
		})
		defer nfs.Close()

		ctx := &AuthContext{
			Credential: &RPCCredential{
				Flavor: AUTH_SYS,
				Body:   nil,
			},
			AuthSys: &AuthSysCredential{
				UID:     1000,
				GID:     1000,
				AuxGIDs: []uint32{1000},
			},
			ClientIP:   "192.168.1.100",
			ClientPort: 1023,
		}
		result := ValidateAuthentication(ctx, nfs.options)
		if result.Allowed {
			t.Error("Expected auth to fail for disallowed IP")
		}
	})
}

// Additional tests for batch processing internal functions
func TestBatchProcessingInternals(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 10
	})
	defer nfs.Close()

	// Create test files
	for i := 0; i < 5; i++ {
		f, _ := mfs.Create("/batchfile" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("batch file content " + string(rune('0'+i))))
		f.Close()
	}

	// Create a directory with files
	mfs.Mkdir("/batchdir", 0755)
	for i := 0; i < 3; i++ {
		f, _ := mfs.Create("/batchdir/file" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("dir file"))
		f.Close()
	}

	t.Run("batch read multiple files", func(t *testing.T) {
		ctx := context.Background()
		for i := 0; i < 5; i++ {
			node, _ := nfs.Lookup("/batchfile" + string(rune('0'+i)) + ".txt")
			handle := nfs.fileMap.Allocate(node)
			data, status, err := nfs.batchProc.BatchRead(ctx, handle, 0, 20)
			if err != nil {
				t.Errorf("BatchRead %d failed: %v", i, err)
			}
			if status != NFS_OK {
				t.Errorf("BatchRead %d status: %d", i, status)
			}
			if len(data) == 0 {
				t.Errorf("BatchRead %d returned empty data", i)
			}
		}
	})

	t.Run("batch write multiple files", func(t *testing.T) {
		ctx := context.Background()
		for i := 0; i < 5; i++ {
			node, _ := nfs.Lookup("/batchfile" + string(rune('0'+i)) + ".txt")
			handle := nfs.fileMap.Allocate(node)
			status, err := nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("updated content"))
			if err != nil {
				t.Errorf("BatchWrite %d failed: %v", i, err)
			}
			if status != NFS_OK {
				t.Errorf("BatchWrite %d status: %d", i, status)
			}
		}
	})

	t.Run("batch getattr multiple files", func(t *testing.T) {
		ctx := context.Background()
		for i := 0; i < 5; i++ {
			node, _ := nfs.Lookup("/batchfile" + string(rune('0'+i)) + ".txt")
			handle := nfs.fileMap.Allocate(node)
			attrs, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
			if err != nil {
				t.Errorf("BatchGetAttr %d failed: %v", i, err)
			}
			if status != NFS_OK {
				t.Errorf("BatchGetAttr %d status: %d", i, status)
			}
			_ = attrs
		}
	})

	t.Run("batch stats collection", func(t *testing.T) {
		enabled, stats := nfs.batchProc.GetStats()
		if !enabled {
			t.Error("Expected batch processing to be enabled")
		}
		_ = stats
	})
}

// Tests for cache TTL updates
func TestCacheTTLOperations(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.AttrCacheTimeout = 100 * time.Millisecond
	})
	defer nfs.Close()

	f, _ := mfs.Create("/ttltest.txt")
	f.Write([]byte("ttl test"))
	f.Close()

	t.Run("update attr cache TTL", func(t *testing.T) {
		// Get the cache
		nfs.mu.RLock()
		cache := nfs.attrCache
		nfs.mu.RUnlock()

		// Get initial entry
		attrs := &NFSAttrs{
			Size: 8,
			Mode: 0644,
			Uid:  1000,
			Gid:  1000,
		}
		cache.Put("/ttltest.txt", attrs)

		// Update TTL
		cache.UpdateTTL(time.Second)
	})

	t.Run("dir cache TTL update", func(t *testing.T) {
		cache := NewDirCache(5*time.Second, 100, 1000)
		cache.Put("/testdir", nil)
		cache.UpdateTTL(time.Second)
	})
}

// Tests for read-ahead buffer edge cases
func TestReadAheadEdgeCases(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.EnableReadAhead = true
		o.ReadAheadSize = 4096
		o.ReadAheadMaxFiles = 5
		o.ReadAheadMaxMemory = 100 * 1024
	})
	defer nfs.Close()

	// Create files of various sizes
	sizes := []int{100, 1000, 10000, 50000}
	for i, size := range sizes {
		content := make([]byte, size)
		for j := range content {
			content[j] = byte((i + j) % 256)
		}
		f, _ := mfs.Create("/sizefile" + string(rune('0'+i)) + ".txt")
		f.Write(content)
		f.Close()
	}

	t.Run("read various file sizes", func(t *testing.T) {
		for i, size := range sizes {
			node, _ := nfs.Lookup("/sizefile" + string(rune('0'+i)) + ".txt")
			data, err := nfs.Read(node, 0, int64(size))
			if err != nil {
				t.Errorf("Read size %d failed: %v", size, err)
			}
			if len(data) != size {
				t.Errorf("Read size %d returned %d bytes", size, len(data))
			}
		}
	})

	t.Run("read-ahead buffer stats", func(t *testing.T) {
		files, memory := nfs.readBuf.Stats()
		t.Logf("ReadAhead stats: files=%d, memory=%d", files, memory)
	})

	t.Run("read-ahead buffer clear", func(t *testing.T) {
		// This exercises the Clear method
		nfs.readBuf.Clear()
	})
}

// Tests for noopLogger methods
func TestNoopLoggerMethods(t *testing.T) {
	logger := &noopLogger{}

	// These should all be no-ops but shouldn't panic
	t.Run("debug", func(t *testing.T) {
		logger.Debug("test message", LogField{Key: "key", Value: "value"})
	})
	t.Run("info", func(t *testing.T) {
		logger.Info("test message", LogField{Key: "key", Value: "value"})
	})
	t.Run("warn", func(t *testing.T) {
		logger.Warn("test message", LogField{Key: "key", Value: "value"})
	})
	t.Run("error", func(t *testing.T) {
		logger.Error("test message", LogField{Key: "key", Value: "value"})
	})
}

// Tests for RecordOperationStart
func TestRecordOperationStartCoverage(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	ops := []string{"READ", "WRITE", "LOOKUP", "CREATE", "REMOVE"}
	for _, op := range ops {
		nfs.RecordOperationStart(op)
	}
}

// Tests for processBatch with various scenarios
func TestProcessBatchScenarios(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 3
	})
	defer nfs.Close()

	// Create test files
	for i := 0; i < 5; i++ {
		f, _ := mfs.Create("/processbatch" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("content for file " + string(rune('0'+i))))
		f.Close()
	}

	t.Run("rapid batch requests", func(t *testing.T) {
		ctx := context.Background()
		for i := 0; i < 10; i++ {
			idx := i % 5
			node, _ := nfs.Lookup("/processbatch" + string(rune('0'+idx)) + ".txt")
			handle := nfs.fileMap.Allocate(node)
			_, _, _ = nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		}
	})
}

// Tests for parseLogLevel function
func TestParseLogLevelCoverage(t *testing.T) {
	tests := []struct {
		input    string
		expected string // We just want no panic
	}{
		{"debug", "debug"},
		{"DEBUG", "debug"},
		{"info", "info"},
		{"INFO", "info"},
		{"warn", "warn"},
		{"WARN", "warn"},
		{"error", "error"},
		{"ERROR", "error"},
		{"invalid", "info"}, // Default
		{"", "info"},        // Default
	}

	for _, tc := range tests {
		t.Run(tc.input, func(t *testing.T) {
			_ = parseLogLevel(tc.input)
		})
	}
}

// Tests for memory monitor pressure handling
func TestMemoryMonitorPressure(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	monitor := NewMemoryMonitor(nfs)

	t.Run("get stats", func(t *testing.T) {
		stats := monitor.GetMemoryStats()
		if stats.totalMemory == 0 {
			// This is fine - depends on system
		}
	})

	t.Run("start and stop", func(t *testing.T) {
		monitor.Start(100 * time.Millisecond)
		time.Sleep(150 * time.Millisecond)
		monitor.Stop()
	})

	t.Run("is active", func(t *testing.T) {
		monitor2 := NewMemoryMonitor(nfs)
		if monitor2.IsActive() {
			t.Error("Should not be active before start")
		}
		monitor2.Start(100 * time.Millisecond)
		if !monitor2.IsActive() {
			t.Error("Should be active after start")
		}
		monitor2.Stop()
	})
}

// Tests for SlogLogger edge cases
func TestSlogLoggerCoverage(t *testing.T) {
	t.Run("new with file path that doesn't exist", func(t *testing.T) {
		// This tests the error path when file can't be created
		// Using a path with null byte which is invalid on all platforms
		config := &LogConfig{
			Level:  "debug",
			Output: "/path/with\x00null/file.log",
		}
		_, err := NewSlogLogger(config)
		if err == nil {
			t.Error("Expected error for invalid file path")
		}
	})

	t.Run("nil config", func(t *testing.T) {
		_, err := NewSlogLogger(nil)
		if err == nil {
			t.Error("Expected error for nil config")
		}
	})
}

// Tests for file handle map operations
func TestFileHandleMapCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/fhtest.txt")
	f.Write([]byte("test"))
	f.Close()

	t.Run("allocate and release handles", func(t *testing.T) {
		node, _ := nfs.Lookup("/fhtest.txt")

		// Allocate handle
		handle := nfs.fileMap.Allocate(node)
		if handle == 0 {
			t.Error("Expected non-zero handle")
		}

		// Get handle
		retrieved, ok := nfs.fileMap.Get(handle)
		if !ok {
			t.Error("Expected to retrieve file")
		}
		_ = retrieved

		// Release handle
		nfs.fileMap.Release(handle)

		// After release, Get should return false
		_, ok = nfs.fileMap.Get(handle)
		if ok {
			t.Error("Expected handle to be released")
		}
	})

	t.Run("count handles", func(t *testing.T) {
		node, _ := nfs.Lookup("/fhtest.txt")
		initialCount := nfs.fileMap.Count()

		handle := nfs.fileMap.Allocate(node)
		newCount := nfs.fileMap.Count()

		if newCount <= initialCount {
			t.Error("Count should increase after allocate")
		}

		nfs.fileMap.Release(handle)
	})

	t.Run("release all", func(t *testing.T) {
		node, _ := nfs.Lookup("/fhtest.txt")
		nfs.fileMap.Allocate(node)
		nfs.fileMap.Allocate(node)
		nfs.fileMap.Allocate(node)

		nfs.fileMap.ReleaseAll()

		if nfs.fileMap.Count() != 0 {
			t.Error("Count should be 0 after ReleaseAll")
		}
	})
}

// Tests for error type detection
func TestErrorTypeDetection(t *testing.T) {
	tests := []struct {
		name       string
		err        error
		isAuth     bool
		isResource bool
	}{
		{"nil error", nil, false, false},
		{"permission denied", os.ErrPermission, true, false}, // os.ErrPermission IS an auth error
		{"not exist", os.ErrNotExist, false, false},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			if isAuthError(tc.err) != tc.isAuth {
				t.Errorf("isAuthError(%v) expected %v", tc.err, tc.isAuth)
			}
			if isResourceError(tc.err) != tc.isResource {
				t.Errorf("isResourceError(%v) expected %v", tc.err, tc.isResource)
			}
		})
	}
}

// More tests for cache eviction and access patterns
func TestCacheAccessPatterns(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.AttrCacheSize = 10 // Small cache to trigger eviction
	})
	defer nfs.Close()

	// Create many files
	for i := 0; i < 20; i++ {
		f, _ := mfs.Create("/cachetest" + string(rune('a'+i)) + ".txt")
		f.Write([]byte("cache test content"))
		f.Close()
	}

	t.Run("cache eviction on overflow", func(t *testing.T) {
		// Lookup all files to fill cache
		for i := 0; i < 20; i++ {
			_, _ = nfs.Lookup("/cachetest" + string(rune('a'+i)) + ".txt")
		}
	})

	t.Run("cache invalidation", func(t *testing.T) {
		nfs.mu.RLock()
		cache := nfs.attrCache
		nfs.mu.RUnlock()

		cache.Invalidate("/cachetest" + string(rune('a')) + ".txt")
		// Invalidate a few more entries individually
		cache.Invalidate("/cachetest" + string(rune('b')) + ".txt")
		cache.Invalidate("/cachetest" + string(rune('c')) + ".txt")
	})
}

// Tests for GetOrError in FileHandleMap - additional coverage
func TestFileHandleMapGetOrErrorCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	f, _ := mfs.Create("/getortest.txt")
	f.Write([]byte("test"))
	f.Close()

	t.Run("valid handle", func(t *testing.T) {
		node, _ := nfs.Lookup("/getortest.txt")
		handle := nfs.fileMap.Allocate(node)

		_, err := nfs.fileMap.GetOrError(handle)
		if err != nil {
			t.Errorf("Expected no error for valid handle: %v", err)
		}

		nfs.fileMap.Release(handle)
	})

	t.Run("invalid handle", func(t *testing.T) {
		_, err := nfs.fileMap.GetOrError(999999)
		if err == nil {
			t.Error("Expected error for invalid handle")
		}
	})
}

// Additional tests for batch request handling
func TestBatchRequestTypes(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create test directory with files
	mfs.Mkdir("/batchdir", 0755)
	for i := 0; i < 5; i++ {
		f, _ := mfs.Create("/batchdir/file" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("batch content"))
		f.Close()
	}

	t.Run("batch directory read", func(t *testing.T) {
		dirNode, _ := nfs.Lookup("/batchdir")
		entries, err := nfs.ReadDir(dirNode)
		if err != nil {
			t.Errorf("ReadDir failed: %v", err)
		}
		if len(entries) == 0 {
			t.Error("Expected directory entries")
		}
	})

	t.Run("batch with timeout context", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()

		node, _ := nfs.Lookup("/batchdir/file0.txt")
		handle := nfs.fileMap.Allocate(node)

		// These should complete before timeout
		_, _, _ = nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		_, _ = nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("new"))
		_, _, _ = nfs.batchProc.BatchGetAttr(ctx, handle)
	})
}

// Tests for more NFS operations
func TestNFSOperationsMore(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	t.Run("create and remove file", func(t *testing.T) {
		rootNode, _ := nfs.Lookup("/")
		attrs := &NFSAttrs{Mode: 0644}

		// Create file
		newNode, err := nfs.Create(rootNode, "createtest.txt", attrs)
		if err != nil {
			t.Errorf("Create failed: %v", err)
		}
		if newNode == nil {
			t.Error("Expected new node")
		}

		// Remove file
		err = nfs.Remove(rootNode, "createtest.txt")
		if err != nil {
			t.Errorf("Remove failed: %v", err)
		}
	})

	t.Run("rename operations", func(t *testing.T) {
		// Create source file
		f, _ := mfs.Create("/renamesrc.txt")
		f.Write([]byte("rename content"))
		f.Close()

		rootNode, _ := nfs.Lookup("/")
		err := nfs.Rename(rootNode, "renamesrc.txt", rootNode, "renamedst.txt")
		if err != nil {
			t.Errorf("Rename failed: %v", err)
		}
	})

	t.Run("setattr operations", func(t *testing.T) {
		f, _ := mfs.Create("/setattrtest.txt")
		f.Write([]byte("setattr content"))
		f.Close()

		node, _ := nfs.Lookup("/setattrtest.txt")
		newAttrs := &NFSAttrs{
			Mode: 0755,
			Size: 15,
		}
		err := nfs.SetAttr(node, newAttrs)
		if err != nil {
			t.Errorf("SetAttr failed: %v", err)
		}
	})
}

// Tests for additional metrics recording
func TestMetricsRecordingMore(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	t.Run("record various events", func(t *testing.T) {
		nfs.RecordAttrCacheHit()
		nfs.RecordAttrCacheMiss()
		nfs.RecordReadAheadHit()
		nfs.RecordReadAheadMiss()
		nfs.RecordDirCacheHit()
		nfs.RecordDirCacheMiss()
	})

	t.Run("get metrics", func(t *testing.T) {
		metrics := nfs.GetMetrics()
		if metrics.TotalOperations < 0 {
			t.Error("Total operations should not be negative")
		}
	})

	t.Run("is healthy", func(t *testing.T) {
		healthy := nfs.IsHealthy()
		if !healthy {
			t.Log("Server reports unhealthy")
		}
	})
}

// Tests for batch SetAttr processing
func TestBatchSetAttrProcessing(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/setattr.txt")
	f.Write([]byte("test content for setattr"))
	f.Close()

	// Lookup and get handle
	node, _ := nfs.Lookup("/setattr.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("setattr batch request", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeSetAttr,
			FileHandle: handle,
			Data:       []byte{}, // Empty attrs for now
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		added, _ := nfs.batchProc.AddRequest(req)
		if !added {
			t.Log("Request wasn't batched, handled inline")
		}

		select {
		case result := <-resultChan:
			if result.Status != NFS_OK && result.Error == nil {
				t.Logf("SetAttr returned status: %d", result.Status)
			}
		case <-time.After(2 * time.Second):
			t.Log("SetAttr request timed out")
		}
	})

	t.Run("setattr with invalid handle", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeSetAttr,
			FileHandle: 999999, // Invalid handle
			Data:       []byte{},
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpected success for invalid handle")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("setattr with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel() // Cancel immediately

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeSetAttr,
			FileHandle: handle,
			Data:       []byte{},
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Error == nil {
				t.Log("Expected cancellation error")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for DirRead batch processing error paths
func TestBatchDirReadErrorPaths(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a regular file (not a directory)
	f, _ := mfs.Create("/notadir.txt")
	f.Write([]byte("regular file"))
	f.Close()

	t.Run("dirread on regular file", func(t *testing.T) {
		ctx := context.Background()
		node, _ := nfs.Lookup("/notadir.txt")
		handle := nfs.fileMap.Allocate(node)

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeDirRead,
			FileHandle: handle,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpectedly succeeded on non-directory")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("dirread with invalid handle", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeDirRead,
			FileHandle: 888888, // Invalid
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpectedly succeeded with invalid handle")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("dirread with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeDirRead,
			FileHandle: 123,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Error == nil {
				t.Log("Expected cancellation error")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for ReadAheadBuffer resize with edge cases
func TestReadAheadBufferResizeEdgeCases(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/resizetest.txt")
	f.Write([]byte("test content for resize operations"))
	f.Close()

	t.Run("resize with zero values", func(t *testing.T) {
		// Should use defaults
		nfs.readBuf.Resize(0, 0)
		files, memory := nfs.readBuf.Stats()
		if files < 0 || memory < 0 {
			t.Error("Stats should not be negative")
		}
	})

	t.Run("resize with negative values", func(t *testing.T) {
		// Should use defaults
		nfs.readBuf.Resize(-1, -1)
		files, memory := nfs.readBuf.Stats()
		if files < 0 || memory < 0 {
			t.Error("Stats should not be negative")
		}
	})

	t.Run("resize with valid values", func(t *testing.T) {
		nfs.readBuf.Resize(50, 1024*1024)
		files, memory := nfs.readBuf.Stats()
		if files < 0 || memory < 0 {
			t.Error("Stats should not be negative")
		}
	})
}

// Tests for batch read error paths
func TestBatchReadErrorPaths(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/readtest.txt")
	f.Write([]byte("test"))
	f.Close()

	t.Run("read with invalid handle", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeRead,
			FileHandle: 777777, // Invalid
			Offset:     0,
			Length:     10,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpectedly succeeded with invalid handle")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("read with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		node, _ := nfs.Lookup("/readtest.txt")
		handle := nfs.fileMap.Allocate(node)
		cancel() // Cancel before request

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeRead,
			FileHandle: handle,
			Offset:     0,
			Length:     10,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Error == nil && result.Status == NFS_OK {
				t.Log("Expected error for cancelled context")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for batch write error paths
func TestBatchWriteErrorPaths(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/writetest.txt")
	f.Write([]byte("test"))
	f.Close()

	t.Run("write with invalid handle", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeWrite,
			FileHandle: 666666, // Invalid
			Offset:     0,
			Data:       []byte("data"),
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpectedly succeeded with invalid handle")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("write with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		node, _ := nfs.Lookup("/writetest.txt")
		handle := nfs.fileMap.Allocate(node)
		cancel()

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeWrite,
			FileHandle: handle,
			Offset:     0,
			Data:       []byte("data"),
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Error == nil && result.Status == NFS_OK {
				t.Log("Expected error for cancelled context")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for read-only mode in batch writes - additional coverage
func TestBatchWriteReadOnlyModeCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
		o.ReadOnly = true
	})
	defer nfs.Close()

	// Create a test file before setting read-only
	f, _ := mfs.Create("/rotest.txt")
	f.Write([]byte("test"))
	f.Close()

	node, _ := nfs.Lookup("/rotest.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("write in readonly mode", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeWrite,
			FileHandle: handle,
			Offset:     0,
			Data:       []byte("write attempt"),
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Error("Should have failed in read-only mode")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for cache UpdateTTL
func TestCacheUpdateTTL(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	f, _ := mfs.Create("/ttltest.txt")
	f.Write([]byte("ttl test"))
	f.Close()

	// Perform lookups to populate cache
	_, _ = nfs.Lookup("/ttltest.txt")

	t.Run("update ttl", func(t *testing.T) {
		nfs.mu.RLock()
		cache := nfs.attrCache
		nfs.mu.RUnlock()

		cache.UpdateTTL(10 * time.Second)
	})
}

// Tests for GetAttr batch error paths
func TestBatchGetAttrErrorPaths(t *testing.T) {
	nfs, _ := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	t.Run("getattr with invalid handle", func(t *testing.T) {
		ctx := context.Background()
		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeGetAttr,
			FileHandle: 555555, // Invalid
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status == NFS_OK {
				t.Log("Unexpectedly succeeded with invalid handle")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})

	t.Run("getattr with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeGetAttr,
			FileHandle: 444444,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Error == nil {
				t.Log("Expected cancellation error")
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for WccAttr encoding
func TestWccAttrEncoding(t *testing.T) {
	t.Run("encode wcc attr", func(t *testing.T) {
		attrs := &NFSAttrs{
			Mode:   0644,
			Size:   12345,
			Uid:    1000,
			Gid:    1000,
			FileId: 42,
		}
		attrs.SetMtime(time.Now())
		attrs.SetAtime(time.Now())

		var buf bytes.Buffer
		err := encodeWccAttr(&buf, attrs)
		if err != nil {
			t.Fatalf("Failed to encode WCC attr: %v", err)
		}

		// WCC attr should be 24 bytes
		if buf.Len() != 24 {
			t.Errorf("Expected 24 bytes, got %d", buf.Len())
		}
	})
}

// Tests for DirCache resize
func TestDirCacheResize(t *testing.T) {
	cache := NewDirCache(5*time.Second, 100, 1000)

	t.Run("resize dir cache", func(t *testing.T) {
		cache.Resize(50)
	})

	t.Run("resize to larger", func(t *testing.T) {
		cache.Resize(200)
	})

	t.Run("resize to zero uses default", func(t *testing.T) {
		cache.Resize(0)
	})
}

// Tests for batching with disabled processor
func TestBatchingDisabled(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = false // Disabled
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/disabled.txt")
	f.Write([]byte("test content"))
	f.Close()

	node, _ := nfs.Lookup("/disabled.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("batch read disabled", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		// Should return immediately with nil/0/nil
		if data != nil || status != 0 || err != nil {
			t.Log("Disabled batch read returned values")
		}
	})

	t.Run("batch write disabled", func(t *testing.T) {
		ctx := context.Background()
		status, err := nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("test"))
		if status != 0 || err != nil {
			t.Log("Disabled batch write returned values")
		}
	})

	t.Run("batch getattr disabled", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if data != nil || status != 0 || err != nil {
			t.Log("Disabled batch getattr returned values")
		}
	})
}

// Tests for AttrCache resize with same size
func TestAttrCacheResizeSameSize(t *testing.T) {
	cache := NewAttrCache(5*time.Second, 100)

	t.Run("resize to same size", func(t *testing.T) {
		cache.Resize(100) // Same as current
		cache.Resize(100) // Again
	})

	t.Run("resize to smaller with eviction", func(t *testing.T) {
		// Add some entries
		for i := 0; i < 50; i++ {
			attrs := &NFSAttrs{Mode: 0644, Size: int64(i)}
			cache.Put("/file"+string(rune('a'+i)), attrs)
		}
		// Now resize smaller to force eviction
		cache.Resize(10)
	})

	t.Run("resize to zero", func(t *testing.T) {
		cache.Resize(0)
	})
}

// Tests for UpdateTTL edge cases
func TestAttrCacheUpdateTTLEdgeCases(t *testing.T) {
	cache := NewAttrCache(5*time.Second, 100)

	t.Run("update ttl to zero", func(t *testing.T) {
		cache.UpdateTTL(0)
	})

	t.Run("update ttl to negative", func(t *testing.T) {
		cache.UpdateTTL(-1 * time.Second)
	})

	t.Run("update ttl to valid", func(t *testing.T) {
		cache.UpdateTTL(10 * time.Second)
	})
}

// Tests for batch context cancellation during wait
func TestBatchContextCancellation(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 100 // Large batch to prevent immediate processing
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/ctx.txt")
	f.Write([]byte("context test"))
	f.Close()

	node, _ := nfs.Lookup("/ctx.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("batch read with context timeout", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond)
		defer cancel()

		// Give time for context to expire
		time.Sleep(5 * time.Millisecond)

		_, status, err := nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		if status == NFS_OK && err == nil {
			t.Log("Expected timeout")
		}
	})

	t.Run("batch write with context timeout", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond)
		defer cancel()

		time.Sleep(5 * time.Millisecond)

		status, err := nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("test"))
		if status == NFS_OK && err == nil {
			t.Log("Expected timeout")
		}
	})

	t.Run("batch getattr with context timeout", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond)
		defer cancel()

		time.Sleep(5 * time.Millisecond)

		_, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if status == NFS_OK && err == nil {
			t.Log("Expected timeout")
		}
	})
}

// Tests for ReadAheadBuffer additional paths
func TestReadAheadBufferPaths(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create test files
	for i := 0; i < 5; i++ {
		f, _ := mfs.Create("/rab" + string(rune('a'+i)) + ".txt")
		f.Write(bytes.Repeat([]byte("x"), 1024))
		f.Close()
	}

	t.Run("read with buffer hit", func(t *testing.T) {
		node, _ := nfs.Lookup("/raba.txt")
		// First read populates buffer
		_, _ = nfs.Read(node, 0, 100)
		// Second read should hit buffer
		_, _ = nfs.Read(node, 50, 100)
	})

	t.Run("clear path", func(t *testing.T) {
		nfs.readBuf.ClearPath("/raba.txt")
	})

	t.Run("configure buffer", func(t *testing.T) {
		nfs.readBuf.Configure(50, 1024*1024)
	})
}

// Tests for encodeFileAttributes error paths
func TestEncodeFileAttributesErrors(t *testing.T) {
	attrs := &NFSAttrs{
		Mode:   0644,
		Size:   1000,
		Uid:    1000,
		Gid:    1000,
		FileId: 123,
	}
	attrs.SetMtime(time.Now())
	attrs.SetAtime(time.Now())

	t.Run("encode with limited writer", func(t *testing.T) {
		// Use a small buffer that will fail mid-encode
		for size := 1; size < 100; size++ {
			buf := make([]byte, size)
			w := &limitedWriter{buf: buf, limit: size}
			_ = encodeFileAttributes(w, attrs) // May or may not error depending on size
		}
	})
}

// limitedWriter is a writer that fails after limit bytes
type limitedWriter struct {
	buf     []byte
	written int
	limit   int
}

func (w *limitedWriter) Write(p []byte) (n int, err error) {
	remaining := w.limit - w.written
	if remaining <= 0 {
		return 0, io.ErrShortWrite
	}
	if len(p) > remaining {
		n = copy(w.buf[w.written:w.written+remaining], p[:remaining])
		w.written += n
		return n, io.ErrShortWrite
	}
	n = copy(w.buf[w.written:w.written+len(p)], p)
	w.written += n
	return n, nil
}

// Tests for batch DirRead success path
func TestBatchDirReadSuccess(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create a directory with files
	mfs.Mkdir("/testdir", 0755)
	for i := 0; i < 3; i++ {
		f, _ := mfs.Create("/testdir/file" + string(rune('0'+i)) + ".txt")
		f.Write([]byte("test"))
		f.Close()
	}

	t.Run("dirread on actual directory", func(t *testing.T) {
		ctx := context.Background()
		node, _ := nfs.Lookup("/testdir")
		handle := nfs.fileMap.Allocate(node)

		resultChan := make(chan *BatchResult, 1)

		req := &BatchRequest{
			Type:       BatchTypeDirRead,
			FileHandle: handle,
			Time:       time.Now(),
			ResultChan: resultChan,
			Context:    ctx,
		}

		nfs.batchProc.AddRequest(req)

		select {
		case result := <-resultChan:
			if result.Status != NFS_OK {
				t.Logf("DirRead returned status: %d", result.Status)
			}
		case <-time.After(2 * time.Second):
			t.Log("Request timed out")
		}
	})
}

// Tests for NFS attribute encoding for different file types
func TestEncodeAttributesForAllTypes(t *testing.T) {
	testCases := []struct {
		name string
		mode os.FileMode
	}{
		{"regular file", 0644},
		{"directory", os.ModeDir | 0755},
		{"symlink", os.ModeSymlink | 0777},
		{"socket", os.ModeSocket | 0755},
		{"named pipe", os.ModeNamedPipe | 0644},
		{"device", os.ModeDevice | 0660},
		{"char device", os.ModeDevice | os.ModeCharDevice | 0660},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			attrs := &NFSAttrs{
				Mode:   tc.mode,
				Size:   1000,
				Uid:    1000,
				Gid:    1000,
				FileId: 42,
			}
			attrs.SetMtime(time.Now())
			attrs.SetAtime(time.Now())

			var buf bytes.Buffer
			err := encodeFileAttributes(&buf, attrs)
			if err != nil {
				t.Fatalf("Failed to encode attributes for %s: %v", tc.name, err)
			}

			// First 4 bytes are file type
			if buf.Len() < 4 {
				t.Fatalf("Buffer too short for %s", tc.name)
			}
		})
	}
}

// Tests for processGetAttrBatch error path
func TestProcessGetAttrBatchErrors(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 5
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/getattrerr.txt")
	f.Write([]byte("test"))
	f.Close()

	node, _ := nfs.Lookup("/getattrerr.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("getattr with valid handle", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if err != nil {
			t.Logf("GetAttr error: %v", err)
		}
		if status != NFS_OK {
			t.Logf("GetAttr status: %d", status)
		}
		if len(data) == 0 {
			t.Log("GetAttr returned no data")
		}
	})
}

// Tests for encodeWccAttr error paths
func TestEncodeWccAttrErrors(t *testing.T) {
	attrs := &NFSAttrs{
		Mode:   0644,
		Size:   1000,
		Uid:    1000,
		Gid:    1000,
		FileId: 123,
	}
	attrs.SetMtime(time.Now())
	attrs.SetAtime(time.Now())

	t.Run("encode with limited writer", func(t *testing.T) {
		// WCC attr is 24 bytes, test failure at each point
		for size := 1; size < 30; size++ {
			buf := make([]byte, size)
			w := &limitedWriter{buf: buf, limit: size}
			_ = encodeWccAttr(w, attrs)
		}
	})
}

// Tests for encodeErrorResponse - additional coverage
func TestEncodeErrorResponseCoverage(t *testing.T) {
	errorCodes := []uint32{
		NFS_OK,
		NFSERR_PERM,
		NFSERR_NOENT,
		NFSERR_IO,
		NFSERR_NXIO,
		NFSERR_ACCES,
		NFSERR_EXIST,
		NFSERR_NODEV,
		NFSERR_NOTDIR,
		NFSERR_ISDIR,
		NFSERR_INVAL,
		NFSERR_FBIG,
		NFSERR_NOSPC,
		NFSERR_ROFS,
		NFSERR_NAMETOOLONG,
		NFSERR_NOTEMPTY,
		NFSERR_STALE,
	}

	for _, code := range errorCodes {
		result := encodeErrorResponse(code)
		if len(result) != 4 {
			t.Errorf("Error response for code %d should be 4 bytes, got %d", code, len(result))
		}
	}
}

// Tests for encodeAttributesResponse
func TestEncodeAttributesResponseCoverage(t *testing.T) {
	attrs := &NFSAttrs{
		Mode:   0644,
		Size:   1000,
		Uid:    1000,
		Gid:    1000,
		FileId: 123,
	}
	attrs.SetMtime(time.Now())
	attrs.SetAtime(time.Now())

	t.Run("encode response", func(t *testing.T) {
		data, err := encodeAttributesResponse(attrs)
		if err != nil {
			t.Fatalf("Failed to encode attributes response: %v", err)
		}
		// Response includes status (4 bytes) + fattr3 (84 bytes)
		if len(data) < 4 {
			t.Errorf("Response too short: %d bytes", len(data))
		}
	})
}

// Tests for ReadAheadBuffer Read edge cases
func TestReadAheadBufferReadEdgeCases(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a file with known content
	content := bytes.Repeat([]byte("abcdefghij"), 100)
	f, _ := mfs.Create("/readedge.txt")
	f.Write(content)
	f.Close()

	node, _ := nfs.Lookup("/readedge.txt")

	t.Run("read at various offsets", func(t *testing.T) {
		// Read at start
		_, _ = nfs.Read(node, 0, 50)
		// Read in middle
		_, _ = nfs.Read(node, 200, 50)
		// Read near end
		_, _ = nfs.Read(node, int64(len(content)-50), 100)
		// Read past end
		_, _ = nfs.Read(node, int64(len(content)), 50)
	})
}

// Tests for cache updateAccessLog
func TestCacheUpdateAccessLog(t *testing.T) {
	cache := NewAttrCache(5*time.Second, 10)

	// Add entries and access them to exercise updateAccessLog
	for i := 0; i < 15; i++ {
		attrs := &NFSAttrs{Mode: 0644, Size: int64(i)}
		cache.Put("/access"+string(rune('a'+i))+".txt", attrs)
	}

	// Access some entries to update access log
	for i := 0; i < 5; i++ {
		cache.Get("/access"+string(rune('a'+i))+".txt", nil)
	}

	// Access same entries again
	for i := 0; i < 5; i++ {
		cache.Get("/access"+string(rune('a'+i))+".txt", nil)
	}
}

// Tests for DirCache updateAccessLog
func TestDirCacheUpdateAccessLog(t *testing.T) {
	cache := NewDirCache(5*time.Second, 10, 1000)

	// Create mock file info
	mockFiles := make([]os.FileInfo, 5)
	for i := range mockFiles {
		mockFiles[i] = &mockFileInfo{name: "file" + string(rune('0'+i)), isDir: false, size: 100}
	}

	// Add entries
	for i := 0; i < 15; i++ {
		cache.Put("/dir"+string(rune('a'+i)), mockFiles)
	}

	// Access some entries
	for i := 0; i < 5; i++ {
		cache.Get("/dir" + string(rune('a'+i)))
	}
}

// mockFileInfo for testing
type mockFileInfo struct {
	name    string
	size    int64
	isDir   bool
	modTime time.Time
}

func (m *mockFileInfo) Name() string       { return m.name }
func (m *mockFileInfo) Size() int64        { return m.size }
func (m *mockFileInfo) Mode() os.FileMode  { return 0644 }
func (m *mockFileInfo) ModTime() time.Time { return m.modTime }
func (m *mockFileInfo) IsDir() bool        { return m.isDir }
func (m *mockFileInfo) Sys() interface{}   { return nil }

// Tests for cache enforceMemoryLimits
func TestCacheEnforceMemoryLimits(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.ReadAheadMaxFiles = 3
		o.ReadAheadMaxMemory = 1024
	})
	defer nfs.Close()

	// Create files larger than limits
	for i := 0; i < 5; i++ {
		content := bytes.Repeat([]byte("x"), 500)
		f, _ := mfs.Create("/limit" + string(rune('a'+i)) + ".txt")
		f.Write(content)
		f.Close()
	}

	// Read all files to fill buffer beyond limits
	for i := 0; i < 5; i++ {
		node, _ := nfs.Lookup("/limit" + string(rune('a'+i)) + ".txt")
		_, _ = nfs.Read(node, 0, 500)
	}
}

// Tests for cache updateAccessOrder
func TestCacheUpdateAccessOrder(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create files
	for i := 0; i < 5; i++ {
		content := bytes.Repeat([]byte("x"), 100)
		f, _ := mfs.Create("/order" + string(rune('a'+i)) + ".txt")
		f.Write(content)
		f.Close()
	}

	// Read files to populate cache
	for i := 0; i < 5; i++ {
		node, _ := nfs.Lookup("/order" + string(rune('a'+i)) + ".txt")
		_, _ = nfs.Read(node, 0, 50)
	}

	// Re-read first files to update access order
	for i := 0; i < 3; i++ {
		node, _ := nfs.Lookup("/order" + string(rune('a'+i)) + ".txt")
		_, _ = nfs.Read(node, 0, 50)
	}
}

// Tests for AddRequest branch coverage
func TestAddRequestBranches(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 2 // Small batch size
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/branch.txt")
	f.Write([]byte("test"))
	f.Close()

	node, _ := nfs.Lookup("/branch.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("add multiple requests to fill batch", func(t *testing.T) {
		ctx := context.Background()

		// Add requests to trigger batch processing
		for i := 0; i < 5; i++ {
			resultChan := make(chan *BatchResult, 1)
			req := &BatchRequest{
				Type:       BatchTypeRead,
				FileHandle: handle,
				Offset:     0,
				Length:     10,
				Time:       time.Now(),
				ResultChan: resultChan,
				Context:    ctx,
			}
			nfs.batchProc.AddRequest(req)
		}

		// Give time for batch processing
		time.Sleep(100 * time.Millisecond)
	})
}

// Tests for IP filtering via ValidateAuthentication
func TestIPFilteringViaAuth(t *testing.T) {
	options := ExportOptions{
		AllowedIPs: []string{"192.168.1.0/24", "10.0.0.1"},
	}

	// Test with various IPs by using ValidateAuthentication
	testCases := []string{
		"192.168.1.100",
		"192.168.1.1",
		"10.0.0.1",
		"10.0.0.2",
		"127.0.0.1",
	}

	for _, ip := range testCases {
		t.Run(ip, func(t *testing.T) {
			ctx := &AuthContext{
				ClientIP: ip,
				Credential: &RPCCredential{
					Flavor: AUTH_SYS,
				},
			}
			_ = ValidateAuthentication(ctx, options)
		})
	}
}

// Tests for unknown batch type
func TestAddRequestUnknownBatchType(t *testing.T) {
	nfs, _ := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
	})
	defer nfs.Close()

	// Create a request with an invalid batch type (very high number)
	req := &BatchRequest{
		Type:       BatchType(255), // Invalid batch type
		FileHandle: 123,
		ResultChan: make(chan *BatchResult, 1),
		Context:    context.Background(),
	}

	added, triggered := nfs.batchProc.AddRequest(req)
	if added || triggered {
		t.Error("Expected AddRequest to return false for unknown batch type")
	}
}

// Tests for batch closed channel scenario
func TestBatchResultChannelClosed(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 1 // Process immediately
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/closedchan.txt")
	f.Write([]byte("test content for closed channel"))
	f.Close()

	node, _ := nfs.Lookup("/closedchan.txt")
	handle := nfs.fileMap.Allocate(node)

	t.Run("batch read with immediate processing", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchRead(ctx, handle, 0, 10)
		if err != nil || status != NFS_OK {
			t.Logf("BatchRead: status=%d, err=%v", status, err)
		}
		if len(data) > 0 {
			t.Logf("BatchRead returned %d bytes", len(data))
		}
	})

	t.Run("batch write with immediate processing", func(t *testing.T) {
		ctx := context.Background()
		status, err := nfs.batchProc.BatchWrite(ctx, handle, 0, []byte("new"))
		if err != nil || status != NFS_OK {
			t.Logf("BatchWrite: status=%d, err=%v", status, err)
		}
	})

	t.Run("batch getattr with immediate processing", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if err != nil || status != NFS_OK {
			t.Logf("BatchGetAttr: status=%d, err=%v", status, err)
		}
		if len(data) > 0 {
			t.Logf("BatchGetAttr returned %d bytes", len(data))
		}
	})
}

// Tests for batch success through Read/Write methods
func TestBatchingThroughNFSOperations(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 1 // Process immediately
	})
	defer nfs.Close()

	// Create test file with content
	testContent := []byte("This is test content for batch through NFS ops")
	f, _ := mfs.Create("/batchnfs.txt")
	f.Write(testContent)
	f.Close()

	node, _ := nfs.Lookup("/batchnfs.txt")

	t.Run("read through NFS with batching", func(t *testing.T) {
		data, err := nfs.Read(node, 0, int64(len(testContent)))
		if err != nil {
			t.Logf("Read error: %v", err)
		}
		if len(data) != len(testContent) {
			t.Logf("Read returned %d bytes, expected %d", len(data), len(testContent))
		}
	})

	t.Run("write through NFS with batching", func(t *testing.T) {
		newData := []byte("Updated content")
		n, err := nfs.Write(node, 0, newData)
		if err != nil {
			t.Logf("Write error: %v", err)
		}
		if n != int64(len(newData)) {
			t.Logf("Write returned %d bytes, expected %d", n, len(newData))
		}
	})
}

// Tests for processGetAttrBatch with file not in cache
func TestProcessGetAttrBatchNotInCache(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.BatchOperations = true
		o.MaxBatchSize = 1
		o.AttrCacheTimeout = 1 * time.Nanosecond // Very short cache
	})
	defer nfs.Close()

	// Create test file
	f, _ := mfs.Create("/notincache.txt")
	f.Write([]byte("test"))
	f.Close()

	node, _ := nfs.Lookup("/notincache.txt")
	handle := nfs.fileMap.Allocate(node)

	// Clear cache
	nfs.mu.RLock()
	nfs.attrCache.Invalidate("/notincache.txt")
	nfs.mu.RUnlock()

	t.Run("getattr with cache miss", func(t *testing.T) {
		ctx := context.Background()
		data, status, err := nfs.batchProc.BatchGetAttr(ctx, handle)
		if err != nil {
			t.Logf("BatchGetAttr error: %v", err)
		}
		if status != NFS_OK {
			t.Logf("BatchGetAttr status: %d", status)
		}
		if len(data) == 0 {
			t.Log("BatchGetAttr returned no data")
		}
	})
}

// Tests for additional cache access patterns
func TestCacheAccessPatternsCoverage(t *testing.T) {
	cache := NewAttrCache(5*time.Second, 5) // Small cache

	// Fill cache to capacity
	for i := 0; i < 5; i++ {
		attrs := &NFSAttrs{Mode: 0644, Size: int64(i * 100)}
		cache.Put("/cap"+string(rune('a'+i))+".txt", attrs)
	}

	// Access middle entries
	for i := 2; i < 4; i++ {
		cache.Get("/cap"+string(rune('a'+i))+".txt", nil)
	}

	// Add more entries to trigger eviction
	for i := 5; i < 10; i++ {
		attrs := &NFSAttrs{Mode: 0644, Size: int64(i * 100)}
		cache.Put("/cap"+string(rune('a'+i))+".txt", attrs)
	}
}

// Tests for ReadAheadBuffer updateAccessOrder path
func TestReadAheadBufferUpdateAccessOrder(t *testing.T) {
	nfs, mfs := createTestServer(t, func(o *ExportOptions) {
		o.ReadAheadMaxFiles = 3 // Small limit
	})
	defer nfs.Close()

	// Create several files
	for i := 0; i < 5; i++ {
		content := bytes.Repeat([]byte(string(rune('a'+i))), 200)
		f, _ := mfs.Create("/accessorder" + string(rune('0'+i)) + ".txt")
		f.Write(content)
		f.Close()
	}

	// Read files sequentially to fill buffer
	for i := 0; i < 5; i++ {
		node, _ := nfs.Lookup("/accessorder" + string(rune('0'+i)) + ".txt")
		_, _ = nfs.Read(node, 0, 100)
	}

	// Re-read earlier files to update access order
	for i := 0; i < 2; i++ {
		node, _ := nfs.Lookup("/accessorder" + string(rune('0'+i)) + ".txt")
		_, _ = nfs.Read(node, 50, 50)
	}
}

// Tests for isAddrInUse
func TestIsAddrInUse(t *testing.T) {
	t.Run("nil error", func(t *testing.T) {
		if isAddrInUse(nil) {
			t.Error("Expected false for nil error")
		}
	})

	t.Run("address in use error", func(t *testing.T) {
		err := &testError{msg: "address already in use"}
		if !isAddrInUse(err) {
			t.Error("Expected true for address in use error")
		}
	})

	t.Run("other error", func(t *testing.T) {
		err := &testError{msg: "some other error"}
		if isAddrInUse(err) {
			t.Error("Expected false for other error")
		}
	})
}

type testError struct {
	msg string
}

func (e *testError) Error() string {
	return e.msg
}

// Tests for ExecuteWithWorker
func TestExecuteWithWorkerCoverage(t *testing.T) {
	t.Run("with worker pool", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.MaxWorkers = 2
		})
		defer nfs.Close()

		result := nfs.ExecuteWithWorker(func() interface{} {
			return 42
		})
		if result != 42 {
			t.Errorf("Expected 42, got %v", result)
		}
	})

	t.Run("without worker pool", func(t *testing.T) {
		nfs, _ := createTestServer(t, func(o *ExportOptions) {
			o.MaxWorkers = 0 // Disabled
		})
		defer nfs.Close()

		result := nfs.ExecuteWithWorker(func() interface{} {
			return "test"
		})
		if result != "test" {
			t.Errorf("Expected 'test', got %v", result)
		}
	})
}

// Tests for GetAttrCacheSize
func TestGetAttrCacheSizeCoverage(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	size := nfs.GetAttrCacheSize()
	if size < 0 {
		t.Error("Cache size should not be negative")
	}
}

// Tests for UpdateExportOptions
func TestUpdateExportOptionsCoverage(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	t.Run("update readonly", func(t *testing.T) {
		newOpts := nfs.GetExportOptions()
		newOpts.ReadOnly = true
		err := nfs.UpdateExportOptions(newOpts)
		if err != nil {
			t.Errorf("Unexpected error: %v", err)
		}
	})

	t.Run("update cache settings", func(t *testing.T) {
		newOpts := nfs.GetExportOptions()
		newOpts.AttrCacheTimeout = 10 * time.Second
		newOpts.AttrCacheSize = 500
		err := nfs.UpdateExportOptions(newOpts)
		if err != nil {
			t.Errorf("Unexpected error: %v", err)
		}
	})
}

// Tests for SetLogger
func TestSetLoggerCoverage(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	t.Run("set nil logger", func(t *testing.T) {
		_ = nfs.SetLogger(nil)
	})
}

// Tests for TLSConfig GetConfig
func TestTLSConfigGetConfigCoverage(t *testing.T) {
	cfg := &TLSConfig{
		CertFile:   "/path/to/cert",
		KeyFile:    "/path/to/key",
		ClientAuth: tls.NoClientCert,
	}

	t.Run("get nil config when not built", func(t *testing.T) {
		// GetConfig returns nil before BuildConfig is called
		result, err := cfg.GetConfig()
		if result != nil || err == nil {
			t.Log("GetConfig returned before build")
		}
	})
}

// Tests for TLSConfig BuildConfig error paths
func TestTLSConfigBuildConfigErrors(t *testing.T) {
	t.Run("missing cert file when enabled", func(t *testing.T) {
		cfg := &TLSConfig{
			Enabled:  true,
			CertFile: "/nonexistent/cert.pem",
			KeyFile:  "/nonexistent/key.pem",
		}
		_, err := cfg.BuildConfig()
		if err == nil {
			t.Error("Expected error for missing cert file")
		}
	})

	t.Run("disabled returns nil", func(t *testing.T) {
		cfg := &TLSConfig{
			Enabled: false,
		}
		result, err := cfg.BuildConfig()
		if result != nil || err != nil {
			t.Error("Expected nil config and nil error when disabled")
		}
	})
}

// Tests for worker pool Submit
func TestWorkerPoolSubmitCoverage(t *testing.T) {
	nfs, _ := createTestServer(t, func(o *ExportOptions) {
		o.MaxWorkers = 1 // Small pool
	})
	defer nfs.Close()

	if nfs.workerPool == nil {
		t.Skip("Worker pool not initialized")
	}

	t.Run("submit multiple tasks", func(t *testing.T) {
		results := make(chan int, 5)
		for i := 0; i < 5; i++ {
			val := i
			nfs.workerPool.Submit(func() interface{} {
				results <- val
				return nil
			})
		}

		// Wait for some results
		time.Sleep(100 * time.Millisecond)
	})
}

// Tests for worker pool Resize
func TestWorkerPoolResizeCoverage(t *testing.T) {
	nfs, _ := createTestServer(t, func(o *ExportOptions) {
		o.MaxWorkers = 2
	})
	defer nfs.Close()

	if nfs.workerPool == nil {
		t.Skip("Worker pool not initialized")
	}

	t.Run("resize larger", func(t *testing.T) {
		nfs.workerPool.Resize(5)
	})

	t.Run("resize smaller", func(t *testing.T) {
		nfs.workerPool.Resize(1)
	})

	t.Run("resize to zero", func(t *testing.T) {
		nfs.workerPool.Resize(0)
	})
}

// Tests for DirCache Get returning multiple values
func TestDirCacheGetCoverage(t *testing.T) {
	cache := NewDirCache(5*time.Second, 100, 1000)

	t.Run("get missing entry", func(t *testing.T) {
		result, ok := cache.Get("/missing")
		if ok || result != nil {
			t.Log("Got result for missing entry")
		}
	})
}

// Tests for validateFilename comprehensive coverage - boost
func TestValidateFilenameCoverageBoost(t *testing.T) {
	testCases := []struct {
		name     string
		input    string
		expected uint32
	}{
		{"empty", "", NFSERR_INVAL},
		{"valid simple", "file.txt", NFS_OK},
		{"valid with spaces", "file with spaces.txt", NFS_OK},
		{"valid with unicode", ".txt", NFS_OK},
		{"too long", string(make([]byte, 300)), NFSERR_NAMETOOLONG},
		{"with null byte", "file\x00name", NFSERR_INVAL},
		{"with forward slash", "path/file", NFSERR_INVAL},
		{"with backslash", "path\\file", NFSERR_INVAL},
		{"dot only", ".", NFSERR_INVAL},
		{"dotdot", "..", NFSERR_INVAL},
		{"valid dotfile", ".hidden", NFS_OK},
		{"valid with numbers", "file123", NFS_OK},
		{"valid with underscore", "file_name", NFS_OK},
		{"valid with dash", "file-name", NFS_OK},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			result := validateFilename(tc.input)
			if result != tc.expected {
				t.Errorf("Expected %d, got %d for input %q", tc.expected, result, tc.input)
			}
		})
	}
}

// Tests for xdrEncodeFileHandle
func TestXdrEncodeFileHandleCoverage(t *testing.T) {
	var buf bytes.Buffer

	t.Run("encode small handle", func(t *testing.T) {
		err := xdrEncodeFileHandle(&buf, 12345)
		if err != nil {
			t.Errorf("Unexpected error: %v", err)
		}
	})

	t.Run("encode max handle", func(t *testing.T) {
		buf.Reset()
		err := xdrEncodeFileHandle(&buf, 0xFFFFFFFFFFFFFFFF)
		if err != nil {
			t.Errorf("Unexpected error: %v", err)
		}
	})
}

// Tests for RecordOperationStart coverage
func TestRecordOperationStartCoverageFull(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	// Record many different operations
	ops := []string{"GETATTR", "SETATTR", "LOOKUP", "ACCESS", "READ", "WRITE", "CREATE", "MKDIR", "REMOVE", "RMDIR"}
	for _, op := range ops {
		done := nfs.RecordOperationStart(op)
		done(nil)
	}

	// Record with errors
	for _, op := range ops {
		done := nfs.RecordOperationStart(op)
		done(os.ErrNotExist)
	}
}

// Tests for Symlink operation
func TestSymlinkCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a file to link to
	f, _ := mfs.Create("/target.txt")
	f.Write([]byte("target content"))
	f.Close()

	rootNode, _ := nfs.Lookup("/")

	t.Run("create symlink", func(t *testing.T) {
		attrs := &NFSAttrs{Mode: 0777 | os.ModeSymlink}
		_, err := nfs.Symlink(rootNode, "link.txt", "/target.txt", attrs)
		if err != nil {
			t.Logf("Symlink error (may be expected if fs doesn't support): %v", err)
		}
	})
}

// Tests for WriteWithContext
func TestWriteWithContextCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/writecontext.txt")
	f.Write([]byte("initial content"))
	f.Close()

	node, _ := nfs.Lookup("/writecontext.txt")

	t.Run("write with context", func(t *testing.T) {
		ctx := context.Background()
		n, err := nfs.WriteWithContext(ctx, node, 0, []byte("new content"))
		if err != nil {
			t.Logf("Write error: %v", err)
		}
		if n > 0 {
			t.Logf("Wrote %d bytes", n)
		}
	})

	t.Run("write with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()
		_, err := nfs.WriteWithContext(ctx, node, 0, []byte("cancelled"))
		if err == nil {
			t.Log("Expected error for cancelled context")
		}
	})
}

// Tests for CreateWithContext
func TestCreateWithContextCoverage(t *testing.T) {
	nfs, _ := createTestServer(t)
	defer nfs.Close()

	rootNode, _ := nfs.Lookup("/")

	t.Run("create with context", func(t *testing.T) {
		ctx := context.Background()
		attrs := &NFSAttrs{Mode: 0644}
		node, err := nfs.CreateWithContext(ctx, rootNode, "created.txt", attrs)
		if err != nil {
			t.Logf("Create error: %v", err)
		}
		if node != nil {
			t.Log("Created file successfully")
		}
	})

	t.Run("create with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()
		attrs := &NFSAttrs{Mode: 0644}
		_, err := nfs.CreateWithContext(ctx, rootNode, "cancelled.txt", attrs)
		if err == nil {
			t.Log("Expected error for cancelled context")
		}
	})
}

// Tests for RemoveWithContext
func TestRemoveWithContextCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a file to remove
	f, _ := mfs.Create("/toremove.txt")
	f.Close()

	rootNode, _ := nfs.Lookup("/")

	t.Run("remove with context", func(t *testing.T) {
		ctx := context.Background()
		err := nfs.RemoveWithContext(ctx, rootNode, "toremove.txt")
		if err != nil {
			t.Logf("Remove error: %v", err)
		}
	})

	t.Run("remove with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()
		err := nfs.RemoveWithContext(ctx, rootNode, "nonexistent.txt")
		if err == nil {
			t.Log("Expected error for cancelled context")
		}
	})
}

// Additional tests for EncodeRPCReply
func TestEncodeRPCReplyCoverage(t *testing.T) {
	t.Run("encode success reply", func(t *testing.T) {
		var buf bytes.Buffer
		reply := &RPCReply{
			Header: RPCMsgHeader{
				Xid:     12345,
				MsgType: 1, // REPLY
			},
			Status:       0,    // MSG_ACCEPTED
			AcceptStatus: 0,    // SUCCESS
			Data:         []byte("test payload"),
		}
		err := EncodeRPCReply(&buf, reply)
		if err != nil {
			t.Errorf("Unexpected error: %v", err)
		}
	})
}

// Tests for ReadWithContext
func TestReadWithContextCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a test file
	f, _ := mfs.Create("/readcontext.txt")
	f.Write([]byte("read context content"))
	f.Close()

	node, _ := nfs.Lookup("/readcontext.txt")

	t.Run("read with context", func(t *testing.T) {
		ctx := context.Background()
		data, err := nfs.ReadWithContext(ctx, node, 0, 20)
		if err != nil {
			t.Logf("Read error: %v", err)
		}
		if len(data) > 0 {
			t.Logf("Read %d bytes", len(data))
		}
	})

	t.Run("read with cancelled context", func(t *testing.T) {
		ctx, cancel := context.WithCancel(context.Background())
		cancel()
		_, err := nfs.ReadWithContext(ctx, node, 0, 20)
		if err == nil {
			t.Log("Expected error for cancelled context")
		}
	})
}

// Tests for Readdir more entries
func TestReaddirMoreCoverage(t *testing.T) {
	nfs, mfs := createTestServer(t)
	defer nfs.Close()

	// Create a directory with many files
	mfs.Mkdir("/manyfiles", 0755)
	for i := 0; i < 20; i++ {
		f, _ := mfs.Create("/manyfiles/file" + string(rune('a'+i)) + ".txt")
		f.Write([]byte("content"))
		f.Close()
	}

	dirNode, _ := nfs.Lookup("/manyfiles")

	t.Run("read large directory", func(t *testing.T) {
		entries, err := nfs.ReadDir(dirNode)
		if err != nil {
			t.Logf("ReadDir error: %v", err)
		}
		t.Logf("Found %d entries", len(entries))
	})
}
